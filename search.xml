<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Cloudflare搭建OpenAI转发脚本</title>
    <url>/posts/7716.html</url>
    <content><![CDATA[
这是一个将兼容OpenAI API的会话请求转发到Github Copilot Chat API的Cloudflare Worker脚本，模型参数仅支持gpt-4和gpt-3.5-turbo，实测使用其他模型均会以默认的3.5处理（对比OpenAI API的返回结果，猜测应该是最早的版本gpt-4-0314和gpt-3.5-turbo-0301）

使用方法
1.  创建一个KV容器



创建命名空间，名字自己起



2.  创建一个Cloudflare Worker




填写自己的worker名称，先创建并部署，一会修改代码



3.  将KV容器绑定到Worker中（可以在Settings -&gt; Variables下找到）


绑定好再做下一步，左值key为变量名称自己起，右值选择kv容器名称

4.  将如下内容粘贴到Worker编辑器页面中
const GithubCopilotChat = GITHUB_COPILOT_CHAT; // 此处替换你绑定KV namespace的名称

addEventListener('fetch', event =&gt; &#123;
  event.respondWith(handleRequest(event.request))
&#125;)

async function handleRequest(request) &#123;
  const corsHeaders = &#123;
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
    'Access-Control-Allow-Headers': '*',
  &#125;

  if (request.method === 'OPTIONS') &#123;
    return new Response(null, &#123;
      status: 200,
      headers: corsHeaders,
    &#125;)
  &#125;

  if (request.method === 'GET') &#123;
    let data = &#123;
      object: &quot;list&quot;,
      data: [
        &#123; &quot;id&quot;: &quot;gpt-4&quot;, &quot;object&quot;: &quot;model&quot;, &quot;created&quot;: 1687882411, &quot;owned_by&quot;: &quot;openai&quot; &#125;,
        &#123; &quot;id&quot;: &quot;gpt-3.5-turbo&quot;, &quot;object&quot;: &quot;model&quot;, &quot;created&quot;: 1677610602, &quot;owned_by&quot;: &quot;openai&quot; &#125;,
      ],
    &#125;
    return new Response(JSON.stringify(data), &#123;
      status: 200,
      headers: corsHeaders,
    &#125;)
  &#125;

  if (request.method !== 'POST') &#123;
    return new Response('Method Not Allowed', &#123;
      status: 405,
      headers: corsHeaders,
    &#125;)
  &#125;

  try &#123;
    const authorizationHeader = request.headers.get('Authorization') || ''
    const match = authorizationHeader.match(/^Bearer\s+(.*)$/)
    if (!match) &#123;
      throw new Error('Missing or malformed Authorization header')
    &#125;
    const githubToken = match[1]

    const copilotToken = await getCopilotToken(githubToken)

    const headers = await createHeaders(copilotToken);

    const requestData = await request.json()

    const openAIResponse = await fetch('https://api.githubcopilot.com/chat/completions', &#123;
      method: 'POST',
      headers: &#123;
        ...headers,
      &#125;,
      body: typeof requestData === 'object' ? JSON.stringify(requestData) : '&#123;&#125;',
    &#125;)

    const &#123; readable, writable &#125; = new TransformStream();
    streamResponse(openAIResponse, writable, requestData);
    return new Response(readable, &#123;
      headers: &#123;
        ...corsHeaders,
        'Content-Type': 'text/event-stream; charset=utf-8',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      &#125;
    &#125;);
  &#125; catch (error) &#123;
    return new Response(error.message, &#123;
      status: 500,
      headers: corsHeaders,
    &#125;);
  &#125;
&#125;

async function streamResponse(openAIResponse, writable, requestData) &#123;
  const reader = openAIResponse.body.getReader();
  const writer = writable.getWriter();
  const encoder = new TextEncoder();
  const decoder = new TextDecoder(&quot;utf-8&quot;);
  let buffer = &quot;&quot;;

  function push() &#123;
    reader.read().then((&#123; done, value &#125;) =&gt; &#123;
      if (done) &#123;
        writer.close();
        return;
      &#125;
      const chunk = decoder.decode(value, &#123; stream: true &#125;);
      let to_send = &quot;&quot;;
      (buffer + chunk).split(&quot;data: &quot;).forEach((raw) =&gt; &#123;
        if (raw === &quot;&quot;)
          return;
        else if (!raw.endsWith(&quot;\n\n&quot;))
          buffer = raw;
        else if (raw.startsWith(&quot;[DONE]&quot;))
          to_send += &quot;data: [DONE]\n\n&quot;;
        else &#123;
          let data = JSON.parse(raw);
          if (data.choices[0].delta?.content === null)
            data.choices[0].delta.content = &quot;&quot;;
          if (data.choices[0].finish_reason === undefined)
            data.choices[0].finish_reason = null;
          if (data.model === undefined &amp;&amp; requestData.model !== undefined)
            data.model = requestData.model;
          if (data.object === undefined)
            data.object = &quot;chat.completion.chunk&quot;;
          to_send += `data: $&#123;JSON.stringify(data)&#125;\n\n`;
        &#125;
      &#125;);
      writer.write(encoder.encode(to_send));
      push();
    &#125;).catch(error =&gt; &#123;
      console.error(error);
      writer.close();
    &#125;);
  &#125;

  push();
&#125;

async function getCopilotToken(githubToken) &#123;
  let tokenData = await GithubCopilotChat.get(githubToken, &quot;json&quot;);
  
  if (tokenData &amp;&amp; tokenData.expires_at * 1000 &gt; Date.now()) &#123;
    return tokenData.token;
  &#125;

  const getTokenUrl = 'https://api.github.com/copilot_internal/v2/token';
  const response = await fetch(getTokenUrl, &#123;
    headers: &#123;
      'Authorization': `token $&#123;githubToken&#125;`, 
      'User-Agent': 'GitHubCopilotChat/0.11.1',
    &#125;
  &#125;);

  if (!response.ok) &#123;
    const errorResponse = await response.text();
    console.error('Failed to get Copilot token from GitHub:', errorResponse);
    throw new Error('Failed to get Copilot token from GitHub:');
  &#125;

  const data = await response.json();

  await GithubCopilotChat.put(githubToken, JSON.stringify(&#123; token: data.token, expires_at: data.expires_at &#125;), &#123;
    expirationTtl: data.expires_at
  &#125;);

  return data.token;
&#125;

async function createHeaders(copilotToken) &#123;
  function genHexStr(length) &#123;
    const arr = new Uint8Array(length / 2);
    crypto.getRandomValues(arr);
    return Array.from(arr, (byte) =&gt; byte.toString(16).padStart(2, '0')).join('');
  &#125;

  return &#123;
    'Authorization': `Bearer $&#123;copilotToken&#125;`,
    'X-Request-Id': `$&#123;genHexStr(8)&#125;-$&#123;genHexStr(4)&#125;-$&#123;genHexStr(4)&#125;-$&#123;genHexStr(4)&#125;-$&#123;genHexStr(12)&#125;`,
    'X-Github-Api-Version': &quot;2023-07-07&quot;,
    'Vscode-Sessionid': `$&#123;genHexStr(8)&#125;-$&#123;genHexStr(4)&#125;-$&#123;genHexStr(4)&#125;-$&#123;genHexStr(4)&#125;-$&#123;genHexStr(25)&#125;`,
    'Vscode-Machineid': genHexStr(64),
    'Editor-Version': 'vscode/1.85.1',
    'Editor-Plugin-Version': 'copilot-chat/0.11.1',
    'Openai-Organization': 'github-copilot',
    'Openai-Intent': 'conversation-panel',
    'Content-Type': 'text/event-stream; charset=utf-8',
    'User-Agent': 'GitHubCopilotChat/0.11.1',
    'Accept': '*/*',
    'Accept-Encoding': 'gzip,deflate,br',
    'Connection': 'close'
  &#125;;
&#125;

5.  修改代码第一行的GITHUB_COPILOT_CHAT为你绑定KV namespace时使用的变量名称

6.  保存并部署Worker

7.  可添加自己的域名解析

]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>GitHub Copilot 快速入门</title>
    <url>/posts/21132.html</url>
    <content><![CDATA[简介

GitHub Copilot 是 AI 结对程序员。 可以使用 GitHub Copilot 在编辑器中获取整行或整个函数的建议。


本指南将介绍如何为个人或组织帐户设置 GitHub Copilot 订阅，在 Visual Studio Code 中安装 GitHub Copilot 扩展，并获得第一个建议。 有关 GitHub Copilot 的详细信息，请参阅“关于 GitHub Copilot Individual”。 有关如何在各种环境中使用 GitHub Copilot 的更深入信息，请参阅“开始使用 GitHub Copilot”。


如果你不是学生、教师或热门开源项目的维护人员，可以在一次性 30 天试用期中免费试用 GitHub Copilot。 免费试用后，需要付费订阅才能继续使用。有关详细信息，请参阅“关于 GitHub Copilot 的计费”。

为个人帐户注册 GitHub Copilot

在开始使用 GitHub Copilot 之前，需要为个人帐户设置免费试用或订阅。


注意****：如果已经使用过 2021 年 7 月至 2022 年 6 月期间提供的免费 GitHub Copilot 技术预览版，则没有资格获得为期 30 天的试用。



在任何页面的右上角，单击个人资料照片，然后单击“设置”。



在边栏的“代码、规划和自动化”部分中，单击“ GitHub Copilot”。


在 GitHub Copilot 设置页面上，单击“启用 GitHub Copilot”。


选择要按月还是按年付款，然后单击“继续访问 Copilot”。

如果个人帐户符合免费 GitHub Copilot 订阅（而不是试用或付费订阅）的条件，将自动转到步骤 6。



按照步骤确认付款详细信息，然后单击“提交”。


选择首选项，然后单击“保存并开始”。
可以稍后通过返回到 GitHub Copilot 设置来更改这些首选项。 有关详细信息，请参阅“在环境中配置 GitHub Copilot”。


注意：如果你作为 GitHub Enterprise Cloud 帐户拥有的组织的成员，拥有 GitHub Copilot 订阅，组织必须为你分配 GitHub Copilot 席位，然后你才能使用 GitHub Copilot。
为组织帐户注册 GitHub Copilot
开始在组织帐户中使用 GitHub Copilot 之前，需要设置订阅。


转到 GitHub Copilot Business 注册页。


选择要为其购买 GitHub Copilot 的组织，然后单击“继续”。


按照步骤确认付款详细信息，然后单击“保存”。
如果文件中没有付款方法，系统将提示你添加一个。


在“公共代码建议”下拉列表中，选择“允许”或“阻止”以允许或阻止与公共代码匹配的建议，然后单击“保存并继续” 。 可以稍后通过返回 GitHub Copilot 设置来更改这些首选项。


为组织中的所有当前和未来用户或组织中的特定用户授予对 GitHub Copilot 的访问权限。

如果选择了“允许所有成员”，请在“确认席位分配”对话框中单击“确认”，以确认要为组织中的所有当前和未来用户启用 GitHub Copilot 。
如果选择了“选定的团队/用户”，则可以选择“添加人员”或“添加团队” 。

如果选择了“添加人员”，则在“为组织所选成员启用 GitHub Copilot 访问权限”对话框中，可以搜索各个成员，也可以通过上传 CSV 文件批量添加成员。
如果选择了“添加团队”，则在“为组织的选定团队启用 GitHub Copilot 访问权限”对话框中，首先在搜索栏中键入团队名称，选择要添加的团队，然后单击“将团队添加到访问列表” 。





要完成 GitHub Copilot Business 订阅的设置，请单击“保存并完成”。 组织成员将收到一封电子邮件，其中包含有关如何开始使用 GitHub Copilot 的说明。


为 Visual Studio Code 安装 GitHub Copilot 扩展

若要使用 GitHub Copilot，必须先安装 Visual Studio Code 扩展。



在 Visual Studio Code 市场中，转到 GitHub Copilot 扩展页，然后单击“安装”。


此时会显示一个弹出窗口，要求打开 Visual Studio Code。 单击“打开 Visual Studio Code”。


在 Visual Studio Code 的“扩展: GitHub Copilot”选项卡中，单击“安装”。


如果以前未在 GitHub 帐户中授权 Visual Studio Code，系统会提示你在 Visual Studio Code 中登录到 GitHub。

如果以前已在 GitHub 帐户中授权 Visual Studio Code，系统将会自动授权 GitHub Copilot。



在浏览器中，GitHub 将请求 GitHub Copilot 所需的权限。 若要批准这些权限，请单击“授权 Visual Studio Code”。


在 Visual Studio Code 的“Visual Studio Code”对话框中，若要确认身份验证，请单击“打开”。


后续步骤
你已成功安装 GitHub Copilot 并收到了你的第一个建议，但这只是开始！ 以下是一些有用的资源，可帮助你对 GitHub Copilot 执行后续操作。

开始使用 GitHub Copilot：你已了解如何在 Visual Studio Code 中获得你的第一个建议。 这些指南介绍了如何在所有受支持的环境中设置和导航 GitHub Copilot 的各种功能。
GitHub Copilot：查看 GitHub Copilot 如何帮助你工作的实用示例。
配置 GitHub Copilot：这些指南提供有关如何将 GitHub Copilot } 配置为个人首选项的详细信息。

其他阅读材料

GitHub Copilot 快速入门

]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>JAVA基础 - HashMap面试题</title>
    <url>/posts/1916.html</url>
    <content><![CDATA[1. 为什么 HashMap 的初始大小是 16，扩容为原来的两倍？

这个问题是用来测试你是否理解 HashMap 的设计原理。HashMap 的初始大小和扩容策略都是为了优化性能。初始大小为 16 是因为它是 2 的整数次幂，可以使得哈希值在哈希表中的分布更均匀。扩容为原来的两倍是因为这样可以保持哈希表的大小始终为 2 的整数次幂，同时避免了频繁的扩容。

2. 为什么 HashMap 在处理哈希冲突时，会在链表长度超过一定阈值时将链表转换为红黑树？

这个问题是用来测试你是否理解 Java 8 中 HashMap 的改进。链表在查找时的时间复杂度是 O(n)，而红黑树在查找时的时间复杂度是 O(log n)，因此当链表长度超过一定阈值时，将链表转换为红黑树可以提高查找性能。

3. 如何解决 HashMap 在多线程环境下的并发问题？

这个问题是用来测试你是否理解 HashMap 的线程安全问题以及解决方案。你需要解释 HashMap 是非线程安全的，如果在多线程环境下需要使用映射数据结构，可以使用 ConcurrentHashMap，它使用分段锁技术来实现高效的并发访问。

4. 什么是负载因子，它的作用是什么？

这个问题是用来测试你是否理解 HashMap 的扩容机制。负载因子是一个浮点数，表示哈希表的填充程度，当哈希表的大小超过了负载因子的阈值时，就会进行扩容。负载因子的选择会影响 HashMap 的性能，一般来说，负载因子越大，空间效率越高，但是查找效率可能会降低。

5. 如果 HashMap 的键是可变的，会有什么问题？

这个问题是用来测试你是否理解 HashMap 的使用注意事项。如果 HashMap 的键是可变的，那么在键的值改变后，可能会导致哈希值改变，从而使得无法正确地从 HashMap 中查找到这个键，因此在使用 HashMap 时，应该尽量避免使用可变对象作为键。
当然，以下是一些更深层次的 HashMap 面试问题：

6. 为什么 HashMap 的初始大小是 16，扩容为原来的两倍？

这个问题是用来测试你是否理解 HashMap 的设计原理。HashMap 的初始大小和扩容策略都是为了优化性能。初始大小为 16 是因为它是 2 的整数次幂，可以使得哈希值在哈希表中的分布更均匀。扩容为原来的两倍是因为这样可以保持哈希表的大小始终为 2 的整数次幂，同时避免了频繁的扩容。

7. 为什么 HashMap 在处理哈希冲突时，会在链表长度超过一定阈值时将链表转换为红黑树？

这个问题是用来测试你是否理解 Java 8 中 HashMap 的改进。链表在查找时的时间复杂度是 O(n)，而红黑树在查找时的时间复杂度是 O(log n)，因此当链表长度超过一定阈值时，将链表转换为红黑树可以提高查找性能。

8. 如何解决 HashMap 在多线程环境下的并发问题？

这个问题是用来测试你是否理解 HashMap 的线程安全问题以及解决方案。你需要解释 HashMap 是非线程安全的，如果在多线程环境下需要使用映射数据结构，可以使用 ConcurrentHashMap，它使用分段锁技术来实现高效的并发访问。

9. 什么是负载因子，它的作用是什么？

这个问题是用来测试你是否理解 HashMap 的扩容机制。负载因子是一个浮点数，表示哈希表的填充程度，当哈希表的大小超过了负载因子的阈值时，就会进行扩容。负载因子的选择会影响 HashMap 的性能，一般来说，负载因子越大，空间效率越高，但是查找效率可能会降低。

10. 如果 HashMap 的键是可变的，会有什么问题？

这个问题是用来测试你是否理解 HashMap 的使用注意事项。如果 HashMap 的键是可变的，那么在键的值改变后，可能会导致哈希值改变，从而使得无法正确地从 HashMap 中查找到这个键，因此在使用 HashMap 时，应该尽量避免使用可变对象作为键。

]]></content>
      <categories>
        <category>JAVA基础</category>
      </categories>
      <tags>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>JAVA基础 - QA</title>
    <url>/posts/21214129.html</url>
    <content><![CDATA[Q/A
1. Java 中应该使用什么数据类型来代表价格?
如果不是特别关心内存和性能的话，使用BigDecimal，否则使用预定义精度的 double 类型。
2. 怎么将 byte 转换为 String?
可以使用 String 接收 byte[] 参数的构造器来进行转换，需要注意的点是要使用的正确的编码，否则会使用平台默认编码，这个编码可能跟原来的编码相同，也可能不同。
3. Java 中怎样将 bytes 转换为 long 类型?
String接收bytes的构造器转成String，再Long.parseLong
4. 我们能将 int 强制转换为 byte 类型的变量吗? 如果该值大于 byte 类型的范围，将会出现什么现象?
是的，我们可以做强制转换，但是 Java 中 int 是 32 位的，而 byte 是 8 位的，所以，如果强制转化是，int 类型的高 24 位将会被丢弃，byte 类型的范围是从 -128 到 127。
5. 存在两个类，B 继承 A，C 继承 B，我们能将 B 转换为 C 么? 如 C = (C) B；
可以，向下转型。但是不建议使用，容易出现类型转型异常.
6. 哪个类包含 clone 方法? 是 Cloneable 还是 Object?
java.lang.Cloneable 是一个标示性接口，不包含任何方法，clone 方法在 object 类中定义。并且需要知道 clone() 方法是一个本地方法，这意味着它是由 c 或 c++ 或 其他本地语言实现的。
7. Java 中 ++ 操作符是线程安全的吗?
不是线程安全的操作。它涉及到多个指令，如读取变量值，增加，然后存储回内存，这个过程可能会出现多个线程交差。还会存在竞态条件(读取-修改-写入)。
8. a = a + b 与 a += b 的区别
在Java中，a = a + b 和 a += b 是两种不同的赋值操作。


a = a + b: 这是一种简单的赋值操作，表示将变量 a 的值与变量 b 的值相加，并将结果赋值给变量 a。例如，如果 a 的初始值为 2，b 的值为 3，则执行 a = a + b 后，a 的值将变为 5。


a += b: 这是一种复合赋值操作，表示将变量 a 的值与变量 b 的值相加，并将结果赋值给变量 a。它相当于 a = a + b 的简化写法。例如，如果 a 的初始值为 2，b 的值为 3，则执行 a += b 后，a 的值也将变为 5。


区别在于赋值操作的方式不同，但最终结果是相同的。而且，使用 a += b 的方式更加简洁和高效，可以提高代码的可读性和执行效率。在实际编程中，可以根据个人的编码风格和习惯选择使用哪种方式。
9. 我能在不进行强制转换的情况下将一个 double 值赋值给 long 类型的变量吗?
不行，你不能在没有强制类型转换的前提下将一个 double 值赋值给 long 类型的变量，因为 double 类型的范围比 long 类型更广，所以必须要进行强制转换。
10. 3*0.1 == 0.3 将会返回什么? true 还是 false?
false，因为有些浮点数不能完全精确的表示出来。
11. int 和 Integer 哪个会占用更多的内存?
Integer 对象会占用更多的内存。Integer 是一个对象，需要存储对象的元数据。但是 int 是一个原始类型的数据，所以占用的空间更少。
12. 为什么 Java 中的 String 是不可变的(Immutable)?
Java 中的 String 不可变是因为 Java 的设计者认为字符串使用非常频繁，将字符串设置为不可变可以允许多个客户端之间共享相同的字符串。更详细的内容参见答案。
13. 我们能在 Switch 中使用 String 吗?
从 Java 7 开始，我们可以在 switch case 中使用字符串，但这仅仅是一个语法糖。内部实现在 switch 中使用字符串的 hash code。
14. Java 中的构造器链是什么?
当你从一个构造器中调用另一个构造器，就是Java 中的构造器链。这种情况只在重载了类的构造器的时候才会出现。
14. 枚举类
JDK1.5出现 每个枚举值都需要调用一次构造函数
15. 什么是不可变对象(immutable object)? Java 中怎么创建一个不可变对象?
不可变对象指对象一旦被创建，状态就不能再改变。任何修改都会创建一个新的对象，如 String、Integer及其它包装类。
如何在Java中写出Immutable的类?
要写出这样的类，需要遵循以下几个原则:
1)immutable对象的状态在创建之后就不能发生改变，任何对它的改变都应该产生一个新的对象。
2)Immutable类的所有的属性都应该是final的。
3)对象必须被正确的创建，比如: 对象引用在对象创建过程中不能泄露(leak)。
4)对象应该是final的，以此来限制子类继承父类，以避免子类改变了父类的immutable特性。
5)如果类中包含mutable类对象，那么返回给客户端的时候，返回该对象的一个拷贝，而不是该对象本身(该条可以归为第一条中的一个特例)
16. 我们能创建一个包含可变对象的不可变对象吗?
是的，我们是可以创建一个包含可变对象的不可变对象的，你只需要谨慎一点，不要共享可变对象的引用就可以了，如果需要变化时，就返回原对象的一个拷贝。最常见的例子就是对象中包含一个日期对象的引用。
17. 有没有可能两个不相等的对象有相同的 hashcode?
有可能，两个不相等的对象可能会有相同的 hashcode 值，这就是为什么在 hashmap 中会有冲突。相等 hashcode 值的规定只是说如果两个对象相等，必须有相同的hashcode 值，但是没有关于不相等对象的任何规定。
18. 两个相同的对象会有不同的 hash code 吗?
不能，根据 hash code 的规定，这是不可能的。
19. 我们可以在 hashcode() 中使用随机数字吗?
不行，因为对象的 hashcode 值必须是相同的。
20. Java 中，Comparator 与 Comparable 有什么不同?
Comparable 接口用于定义对象的自然顺序，而 comparator 通常用于定义用户定制的顺序。Comparable 总是只有一个，但是可以有多个 comparator 来定义对象的顺序。
21. 为什么在重写 equals 方法的时候需要重写 hashCode 方法?
因为有强制的规范指定需要同时重写 hashcode 与 equals 是方法，许多容器类，如 HashMap、HashSet 都依赖于 hashcode 与 equals 的规定。
22. “a==b”和”a.equals(b)”有什么区别?
如果 a 和 b 都是对象，则 a==b 是比较两个对象的引用，只有当 a 和 b 指向的是堆中的同一个对象才会返回 true，而 a.equals(b) 是进行逻辑比较，所以通常需要重写该方法来提供逻辑一致性的比较。例如，String 类重写 equals() 方法，所以可以用于两个不同对象，但是包含的字母相同的比较。
23. a.hashCode() 有什么用? 与 a.equals(b) 有什么关系?
简介: hashCode() 方法是相应对象整型的 hash 值。它常用于基于 hash 的集合类，如 Hashtable、HashMap、LinkedHashMap等等。它与 equals() 方法关系特别紧密。根据 Java 规范，两个使用 equals() 方法来判断相等的对象，必须具有相同的 hash code。
1、hashcode的作用
List和Set，如何保证Set不重复呢? 通过迭代使用equals方法来判断，数据量小还可以接受，数据量大怎么解决? 引入hashcode，实际上hashcode扮演的角色就是寻址，大大减少查询匹配次数。
2、hashcode重要吗
对于数组、List集合就是一个累赘。而对于hashmap, hashset, hashtable就异常重要了。
3、equals方法遵循的原则

对称性 若x.equals(y)true，则y.equals(x)true
自反性 x.equals(x)必须true
传递性 若x.equals(y)true,y.equals(z)true,则x.equals(z)必为true
一致性 只要x,y内容不变，无论调用多少次结果不变
其他 x.equals(null) 永远false，x.equals(和x数据类型不同)始终false

24. final、finalize 和 finally 的不同之处?

final 是一个修饰符，可以修饰变量、方法和类。如果 final 修饰变量，意味着该变量的值在初始化后不能被改变。
Java 技术允许使用 finalize() 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在确定这个对象没有被引用时对这个对象调用的，但是什么时候调用 finalize 没有保证。
finally 是一个关键字，与 try 和 catch 一起用于异常的处理。finally 块一定会被执行，无论在 try 块中是否有发生异常。

25. Java 中的编译期常量是什么? 使用它又什么风险?
变量也就是我们所说的编译期常量，这里的 public 可选的。实际上这些变量在编译时会被替换掉，因为编译器知道这些变量的值，并且知道这些变量在运行时不能改变。这种方式存在的一个问题是你使用了一个内部的或第三方库中的公有编译时常量，但是这个值后面被其他人改变了，但是你的客户端仍然在使用老的值，甚至你已经部署了一个新的jar。为了避免这种情况，当你在更新依赖 JAR 文件时，确保重新编译你的程序。
26. 静态内部类与顶级类有什么区别?
一个公共的顶级类的源文件名称与类名相同，而嵌套静态类没有这个要求。一个嵌套类位于顶级类内部，需要使用顶级类的名称来引用嵌套静态类，如 HashMap.Entry 是一个嵌套静态类，HashMap 是一个顶级类，Entry是一个嵌套静态类。
27. Java 中，Serializable 与 Externalizable 的区别?
Serializable 接口是一个序列化 Java 类的接口，以便于它们可以在网络上传输或者可以将它们的状态保存在磁盘上，是 JVM 内嵌的默认序列化方式，成本高、脆弱而且不安全。Externalizable 允许你控制整个序列化过程，指定特定的二进制格式，增加安全机制。
28. 说出 JDK 1.7 中的三个新特性?
虽然 JDK 1.7 不像 JDK 5 和 8 一样的大版本，但是，还是有很多新的特性，如 try-with-resource 语句，这样你在使用流或者资源的时候，就不需要手动关闭，Java 会自动关闭。Fork-Join 池某种程度上实现 Java 版的 Map-reduce。允许 Switch 中有 String 变量和文本。菱形操作符(&lt;&gt;)用于泛型推断，不再需要在变量声明的右边申明泛型，因此可以写出可读写更强、更简洁的代码。另一个值得一提的特性是改善异常处理，如允许在同一个 catch 块中捕获多个异常。
29. 说出 5 个 JDK 1.8 引入的新特性?
Java 8 在 Java 历史上是一个开创新的版本，下面 JDK 8 中 5 个主要的特性: Lambda 表达式，允许像对象一样传递匿名函数 Stream API，充分利用现代多核 CPU，可以写出很简洁的代码 Date 与 Time API，最终，有一个稳定、简单的日期和时间库可供你使用 扩展方法，现在，接口中可以有静态、默认方法。 重复注解，现在你可以将相同的注解在同一类型上使用多次。
下述包含 Java 面试过程中关于 SOLID 的设计原则，OOP 基础，如类，对象，接口，继承，多态，封装，抽象以及更高级的一些概念，如组合、聚合及关联。也包含了 GOF 设计模式的问题。
30. 接口是什么? 为什么要使用接口而不是直接使用具体类?
接口用于定义 API。它定义了类必须得遵循的规则。同时，它提供了一种抽象，因为客户端只使用接口，这样可以有多重实现，如 List 接口，你可以使用可随机访问的 ArrayList，也可以使用方便插入和删除的 LinkedList。接口中不允许普通方法，以此来保证抽象，但是 Java 8 中你可以在接口声明静态方法和默认普通方法。
31. Java 中，抽象类与接口之间有什么不同?
Java 中，抽象类和接口有很多不同之处，但是最重要的一个是 Java 中限制一个类只能继承一个类，但是可以实现多个接口。抽象类可以很好的定义一个家族类的默认行为，而接口能更好的定义类型，有助于后面实现多态机制 参见第六条。
32. Object有哪些公用方法?
clone equals hashcode wait notify notifyall finalize toString getClass 除了clone和finalize其他均为公共方法。
11个方法，wait被重载了两次
33. equals与==的区别
区别1. ==是一个运算符 equals是Object类的方法
区别2. 比较时的区别

用于基本类型的变量比较时: ==用于比较值是否相等，equals不能直接用于基本数据类型的比较，需要转换为其对应的包装类型。
用于引用类型的比较时。==和equals都是比较栈内存中的地址是否相等 。相等为true 否则为false。但是通常会重写equals方法去实现对象内容的比较。

34. String、StringBuffer与StringBuilder的区别
第一点: 可变和适用范围。String对象是不可变的，而StringBuffer和StringBuilder是可变字符序列。每次对String的操作相当于生成一个新的String对象，而对StringBuffer和StringBuilder的操作是对对象本身的操作，而不会生成新的对象，所以对于频繁改变内容的字符串避免使用String，因为频繁的生成对象将会对系统性能产生影响。
第二点: 线程安全。String由于有final修饰，是immutable的，安全性是简单而纯粹的。StringBuilder和StringBuffer的区别在于StringBuilder不保证同步，也就是说如果需要线程安全需要使用StringBuffer，不需要同步的StringBuilder效率更高。
35. switch能否用String做参数
Java1.7开始支持，但实际这是一颗Java语法糖。除此之外，byte，short，int，枚举均可用于switch，而boolean和浮点型不可以。
36. 接口与抽象类

一个子类只能继承一个抽象类, 但能实现多个接口
抽象类可以有构造方法, 接口没有构造方法
抽象类可以有普通成员变量, 接口没有普通成员变量
抽象类和接口都可有静态成员变量, 抽象类中静态成员变量访问类型任意，接口只能public static final(默认)
抽象类可以没有抽象方法, 抽象类可以有普通方法；接口在JDK8之前都是抽象方法，在JDK8可以有default方法，在JDK9中允许有私有普通方法
抽象类可以有静态方法；接口在JDK8之前不能有静态方法，在JDK8中可以有静态方法，且只能被接口类直接调用（不能被实现类的对象调用）
抽象类中的方法可以是public、protected; 接口方法在JDK8之前只有public abstract，在JDK8可以有default方法，在JDK9中允许有private方法

37. 抽象类和最终类
抽象类可以没有抽象方法, 最终类可以没有最终方法
最终类不能被继承, 最终方法不能被重写(可以重载)
38. 异常
相关的关键字 throw、throws、try…catch、finally

throws 用在方法签名上, 以便抛出的异常可以被调用者处理
throw 方法内部通过throw抛出异常
try 用于检测包住的语句块, 若有异常, catch子句捕获并执行catch块

39. 关于finally

finally不管有没有异常都要处理
当try和catch中有return时，finally仍然会执行，finally比return先执行
不管有木有异常抛出, finally在return返回前执行
finally是在return后面的表达式运算后执行的(此时并没有返回运算后的值，而是先把要返回的值保存起来，管finally中的代码怎么样，返回的值都不会改变，仍然是之前保存的值)，所以函数返回值是在finally执行前确定的

注意: finally中最好不要包含return，否则程序会提前退出，返回值不是try或catch中保存的返回值
finally不执行的几种情况: 程序提前终止如调用了System.exit, 病毒，断电
40. 受检查异常和运行时异常

受检查的异常(checked exceptions),其必须被try…catch语句块所捕获, 或者在方法签名里通过throws子句声明。受检查的异常必须在编译时被捕捉处理,命名为Checked Exception是因为Java编译器要进行检查, Java虚拟机也要进行检查, 以确保这个规则得到遵守。

常见的checked exception: ClassNotFoundException IOException FileNotFoundException EOFException

运行时异常(runtime exceptions), 需要程序员自己分析代码决定是否捕获和处理,比如空指针,被0除…

常见的runtime exception: NullPointerException ArithmeticException ClassCastException IllegalArgumentException IllegalStateException IndexOutOfBoundsException NoSuchElementException

Error的，则属于严重错误，如系统崩溃、虚拟机错误、动态链接失败等，这些错误无法恢复或者不可能捕捉，将导致应用程序中断，Error不需要捕获。

41. super出现在父类的子类中。有三种存在方式

super.xxx(xxx为变量名或对象名)意思是获取父类中xxx的变量或引用
super.xxx(); (xxx为方法名)意思是直接访问并调用父类中的方法
super() 调用父类构造

注: super只能指代其直接父类
42. this() &amp; super()在构造方法中的区别

调用super()必须写在子类构造方法的第一行, 否则编译不通过
super从子类调用父类构造, this在同一类中调用其他构造均需要放在第一行
尽管可以用this调用一个构造器, 却不能调用2个
this和super不能出现在同一个构造器中, 否则编译不通过
this()、super()都指的对象,不可以在static环境中使用
本质this指向本对象的指针。super是一个关键字

43. 构造内部类和静态内部类对象
在Java中，我们可以使用以下方式来构造内部类和静态内部类的对象：


构造内部类对象：

如果内部类是非静态的，我们需要先创建外部类的对象，然后使用外部类对象来创建内部类对象。例如：OuterClass outerObj = new OuterClass(); InnerClass innerObj = outerObj.new InnerClass();
如果内部类是静态的，我们可以直接使用外部类名来创建内部类的对象。例如：OuterClass.InnerClass innerObj = new OuterClass.InnerClass();



构造静态内部类对象：

静态内部类与外部类之间没有直接的依赖关系，所以我们可以直接使用外部类名来创建静态内部类的对象。例如：OuterClass.StaticInnerClass innerObj = new OuterClass.StaticInnerClass();



需要注意的是，内部类与外部类之间的访问权限规则适用于内部类对象的构造。例如，如果内部类是私有的，则只能在外部类的内部进行构造操作；如果内部类是公共的，则可以在任何地方进行构造操作。
此外，还需要注意内部类对象的生命周期与外部类对象的关系，内部类对象的生存期可以超过外部类对象的生存期。
静态内部类不需要有指向外部类的引用。但非静态内部类需要持有对外部类的引用。非静态内部类能够访问外部类的静态和非静态成员。静态内部类不能访问外部类的非静态成员，只能访问外部类的静态成员。
44. 序列化
声明为static和transient类型的数据不能被序列化， 反序列化需要一个无参构造函数
45. Java移位运算符
java中有三种移位运算符

&lt;&lt; :左移运算符,x &lt;&lt; 1,相当于x乘以2(不溢出的情况下),低位补0
&gt;&gt; :带符号右移,x &gt;&gt; 1,相当于x除以2,正数高位补0,负数高位补1
&gt;&gt;&gt; :无符号右移,忽略符号位,空位都以0补齐

46. 形参&amp;实参
形式参数可被视为local variable.形参和局部变量一样都不能离开方法。只有在方法中使用，不会在方法外可见。 形式参数只能用final修饰符，其它任何修饰符都会引起编译器错误。但是用这个修饰符也有一定的限制，就是在方法中不能对参数做任何修改。不过一般情况下，一个方法的形参不用final修饰。只有在特殊情况下，那就是: 方法内部类。一个方法内的内部类如果使用了这个方法的参数或者局部变量的话，这个参数或局部变量应该是final。 形参的值在调用时根据调用者更改，实参则用自身的值更改形参的值(指针、引用皆在此列)，也就是说真正被传递的是实参。
47. 局部变量为什么要初始化
局部变量是指类方法中的变量，必须初始化。局部变量运行时被分配在栈中，量大，生命周期短，如果虚拟机给每个局部变量都初始化一下，是一笔很大的开销，但变量不初始化为默认值就使用是不安全的。出于速度和安全性两个方面的综合考虑，解决方案就是虚拟机不初始化，但要求编写者一定要在使用前给变量赋值。
48. Java语言的鲁棒性
Java在编译和运行程序时，都要对可能出现的问题进行检查，以消除错误的产生。它提供自动垃圾收集来进行内存管理，防止程序员在管理内存时容易产生的错误。通过集成的面向对象的例外处理机制，在编译时，Java揭示出可能出现但未被处理的异常，帮助程序员正确地进行选择以防止系统的崩溃。另外，Java在编译时还可捕获类型声明中的许多常见错误，防止动态运行时不匹配问题的出现。
后续更新


以上内容部分为ChatGpt4生成
参考https://pdai.tech/md/java/basic/java-basic-lan-sum.html

]]></content>
      <categories>
        <category>JAVA基础</category>
      </categories>
      <tags>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>JAVA基础 - 初识HashMap</title>
    <url>/posts/47159.html</url>
    <content><![CDATA[大纲：


基本概念和原理

什么是 HashMap？
HashMap 的基本工作原理是什么？
HashMap 和 HashTable、TreeMap 的区别是什么？



底层数据结构

HashMap 的底层数据结构是什么？
为什么选择这种数据结构？
如何处理哈希冲突？



哈希函数

HashMap 的哈希函数是如何工作的？
为什么要使用 (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16) 这样的哈希函数？
这种哈希函数的优点和缺点是什么？



寻址算法

HashMap 的寻址算法是如何工作的？
为什么要使用 (n - 1) &amp; hash 这样的寻址算法？
这种寻址算法的优点和缺点是什么？



扩容机制

HashMap 的扩容机制是如何工作的？
什么时候会触发扩容？
扩容的过程中会发生什么？



线程安全性问题

HashMap 是线程安全的吗？
如果不是，那么在多线程环境下如何使用 HashMap？
ConcurrentHashMap 和 Collections.synchronizedMap() 是如何解决 HashMap 线程安全问题的？



性能优化

如何优化 HashMap 的性能？
初始化大小、加载因子等参数的选择对性能有什么影响？



使用注意事项

在使用 HashMap 时需要注意哪些问题？
哪些场景下应该使用 HashMap，哪些场景下不应该使用 HashMap？



Java 8中的改进

在Java 8中，HashMap 有哪些改进？
这些改进对 HashMap 的性能有什么影响？




1. 基本概念和原理
1.1 什么是 HashMap？

HashMap 是 Java 中的一种基本数据结构，它属于 Java 集合框架的一部分。它用于存储键值对，其中每个键都是唯一的。HashMap 的主要优点是它允许以常数时间复杂度进行插入、删除和定位操作，这是通过使用哈希表实现的。

1.2 HashMap 的基本工作原理是什么？

HashMap 的工作原理基于哈希表。当我们向 HashMap 添加一个元素时，HashMap 会使用哈希函数计算键的哈希码，这个哈希码决定了元素在哈希表中的位置。如果两个元素的键产生相同的哈希码，那么它们会被放在同一个桶中，这种情况称为哈希冲突。HashMap 通过链表和红黑树（Java 8之后）解决冲突。

1.3 HashMap 和 HashTable、TreeMap 的区别是什么？

HashMap、HashTable 和 TreeMap 都是 Java 中的映射数据结构，但它们有一些关键的区别。HashMap 允许键和值为 null，而 HashTable 不允许。HashMap 是非线程安全的，而 HashTable 是线程安全的。而 TreeMap 是基于红黑树的，它的键必须实现 Comparable 接口，元素的插入和查找时间复杂度为 $O(\log n)$，而 HashMap 和 HashTable 的插入和查找时间复杂度通常为 $O(1)$。

2. 底层数据结构
2.1 HashMap 的底层数据结构是什么？

HashMap 的底层是由数组和链表（或红黑树）组成的哈希表。数组的每个元素都是一个链表或红黑树的头节点。当我们插入一个新的键值对时，HashMap 会计算键的哈希值，然后用这个哈希值决定键值对在数组中的位置。如果该位置已经有其他键值对（哈希冲突），那么新的键值对就会被添加到这个位置的链表或红黑树中。

2.2 为什么选择这种数据结构？

这种数据结构的选择主要基于以下两个原因：首先，数组的索引可以直接映射到哈希值，使得查找操作的时间复杂度为 $O(1)$。其次，使用链表或红黑树可以解决哈希冲突的问题。链表适合处理冲突较少的情况，而红黑树适合处理冲突较多的情况（即链表长度大于一定阈值时）。

2.3 如何处理哈希冲突？

当两个不同的键的哈希值相同时，会发生哈希冲突。HashMap 使用链地址法处理哈希冲突，即将哈希值相同的键值对链接在一起形成一个链表。在 Java 8 中，如果链表的长度超过一定阈值（默认为 8），那么链表就会被转换为红黑树，以提高搜索效率。

3. 哈希函数
3.1 HashMap 的哈希函数是如何工作的？

HashMap 的哈希函数主要是用于计算键的哈希值。在 HashMap 中，哈希函数的主要作用是将任意长度的输入（即键）通过哈希算法转换成固定长度的输出，即哈希值。这个哈希值用于确定键值对在数组中的位置。

3.2 为什么要使用 (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16) 这样的哈希函数？

这种哈希函数是为了进一步确保对象分布均匀，减少哈希冲突的概率。key.hashCode() 是通过调用键的 hashCode 方法获取哈希值，(h &gt;&gt;&gt; 16) 是将哈希值右移16位。通过异或操作 ^，可以在不改变哈希值的情况下，使得高位和低位混合，从而达到更好的分布效果。

3.3 这种哈希函数的优点和缺点是什么？

优点是能够使得哈希值的分布更均匀，减少哈希冲突的概率，从而提高 HashMap 的性能。缺点是计算稍微复杂一些，可能会增加一些计算开销，但考虑到其带来的性能提升，这个开销通常是可以接受的。

4. 寻址算法
4.1 什么是 HashMap 的寻址算法？

当我们往 HashMap 中添加一个元素（键值对）时，首先需要确定这个元素应该存储在数组的哪个位置，这一决定由寻址算法来实现。具体来讲，这个算法会使用哈希函数处理过的哈希码(hash code)来决定键值对在数组的存储索引位置。

4.2 为什么要使用 (n - 1) &amp; hash 这样的寻址算法？

HashMap 的数组长度总是2的幂次方，这样设计是为了提高寻址效率。算法 (n - 1) &amp; hash 中，n 是数组的大小，hash 是键的哈希码。由于 n 是2的幂次方，n - 1 的二进制表示将为一系列的1。这时候，n - 1 与 hash 进行 &amp; 操作可以看做是对 hash 进行余数操作，这种方式快速地定位了元素所在的桶的位置，同时确保了分布的均匀性。如果简单地使用取模运算（即hash % n），会由于%操作本身较低的效率而降低寻址速度。

4.3 这种寻址算法的优点和缺点是什么？

优点

高效：与常规的取模运算相比，位运算具有更高的效率。
分布均匀：因为长度是2的幂次方，所以索引生成的结果经过位运算后更加分散。



缺点

大小限制：数组的大小必须是2的幂次方，这会对内存设计造成一定的约束。
负载变重时性能降低：随着数据量变大，冲突增多，性能可能变差一些。但通常情况下，合理的扩容和负载因子可以在一定程度上缓解这个问题。


5. 扩容机制
5.1 什么是 HashMap 的扩容？

当我们谈论 HashMap 的扩容机制时，我们指的是它增加内部存储结构的大小以适应更多元素的过程。正如人们需要更大的居住空间来放置更多的家具一样，HashMap 需要更多的空间来存储更多的键值对（键-值对）。

5.2 HashMap 的扩容机制是如何工作的？

在 HashMap 中，当我们将键值对加入集合中，如果存储的数量达到某个阈值（默认是桶的数量的 0.75，也就是加载因子的75%），HashMap 就会开始一个扩容的过程。在这个过程中，内部的存储桶数量会增加到原来的两倍，这样做是为了减少潜在的哈希冲突，以及维持集合的存取效率。

5.3 什么时候会触发扩容？

类似于一艘船超重可能会沉没，HashMap 如果超过负荷就需要扩容。扩容通常发生在插入操作之后检查到 HashMap中存储的元素数量超过了“容量 * 加载因子”所定义的阈值。加载因子默认值是0.75，这代表了当桶(bucket)有75%被占用时进行扩容，这可以保证空间和时间效率的平衡。

5.4 扩容的过程中会发生什么？

在 HashMap 扩容时，首先，内部的存储桶数组大小会增加到原来的两倍，并创建一个新的桶数组来替代旧的。然后 HashMap要把已有的数据迁移到这个新的数组中去, 每个已存在元素的位置也许会改变，因为它们的哈希可能会在新数组中映射到不同的位置。这是一个成本较高的操作，因为它涉及到重新计算每个元素的哈希并定位到新的桶中，入不敷出会显著降低性能，所以应当尽可能避免频繁扩容。

5.5 扩容为什么重要，以及它的影响？

扩容是维持 HashMap 性能的一个重要过程。适时的扩容可以防止哈希冲突的增加，冲突过多会导致数据的存取效率变差（从常数时间退化到线性时间）。不过，频繁的扩容也会带来性能下降，因为扩容是一个重量级的操作，所以合理设置初始容量和加载因子是非常重要的。

6. 线程安全性问题
6.1 HashMap 是线程安全的吗？

不，HashMap 不是线程安全的。这意味着如果多个线程同时尝试修改 HashMap 的结构，例如添加或删除键值对，而没有进行适当的外部同步，那么 HashMap 的一致性可能被破坏，导致不可预知的行为或数据丢失。

6.2 如果不是，那么在多线程环境下如何使用 HashMap？

在需求允许的情况下，可以使用 Collections.synchronizedMap() 方法将 HashMap 包装起来创建一个同步的映射。这样可以保证多个线程操作这个集合时，对集合的操作是互斥的。例如，通过下面的代码段可以创建一个同步的 HashMap：

Map&lt;K,V&gt; map = Collections.synchronizedMap(new HashMap&lt;K,V&gt;());

不过需要注意，虽然每个方法调用都被同步了，但是对集合的复合操作仍然需要外部同步管理来防止并发问题。

另一个选择是使用 ConcurrentHashMap 类，这是 java.util.concurrent 包提供的一种线程安全的HashMap实现。它通过分割数据结构以及利用细粒度的锁和同步器，比如 Lock 和 ReadWrite 锁，在保持高并发性能的同时提供线程安全性。

6.3 ConcurrentHashMap 和 Collections.synchronizedMap() 是如何解决 HashMap 线程安全问题的？

ConcurrentHashMap 和 Collections.synchronizedMap() 都提供了对多线程环境下 HashMap 操作的同步控制，但他们的实现方式和设计目标不一样。

Collections.synchronizedMap(): 它提供了一种同步的map，保护方法调用，防止多个线程同时对 HashMap 进行修改引发不一致状态。虽然它确保线程安全，但在高并发场合下，性能可能会下降，因为每次只有一个线程能够访问map。
ConcurrentHashMap: 这是一个为高并发优化的线程安全HashMap实现。它使用了一个分段锁（Segmentation Lock）机制，这种机制允许多个线程并发地访问不同段的buckets，从而降低锁竞争，提高并发度。此外，访问和更新操作不需要锁住整个map，只需要部分对锁的控制，并且读操作过程中通常完全不需要锁，从而具有更高的并发性能。


7. 性能优化
7.1 如何优化 HashMap 的性能？

对 HashMap 进行性能优化涉及到为它提供合适的初始化参数和良好的使用实践。一个很重要的策略是合理预估存储元素数量，并相应地初始化 HashMap 的初始容量（initial capacity），这样可以减小扩容次数。还应注意选择合适的加载因子（load factor），对于执行多次插入操作的 HashMap，较低的加载因子可以减少哈希冲突，但同时会增加内存占用。

7.2 初始化大小、加载因子等参数的选择对性能有什么影响？

确定合适的初始化大小和加载因子可以极大影响 HashMap 的性能。HashMap 的默认加载因子 是 0.75，这是时间和空间成本的一种折中选择。较高的加载因子可能会减少内存使用，但同时增加了哈希冲突，从而减少性能，特别是在填充程度较高的情况下尤其明显。如果对内存使用没有特别严格的要求，可以适当降低加载因子来得到更好的性能。
同样，初始容量若预设不当，可能会在HashMap在后期的使用过程中需要进行多次成本较高的扩容操作。反之，如果初始容量设置过大，又可能会浪费内存资源。假如能够较为精确估计HashMap将要存储的元素数量，设置一个适当的初始容量可以减少自动扩容的次数，从而优化性能表现。所以，找到合适的容量和加载因子是实现HashMap性能优化的关键。

8. 使用注意事项
8.1. 键值对的唯一性与null值的处理

在HashMap中，每一个键值对被视为一个单独的实体，这被称作“映射条目”。每个键（Key）是独一无二的，而值（Value）可以重复。HashMap允许你将null作为一个键或者值，但是要特别小心，因为过多地使用null可能会降低映射的可读性，并可能导致潜在的错误。

8.2. 注意hashCode()与equals()的实现

正确覆写hashCode()和equals()方法是使用HashMap的关键。这是因为HashMap使用键对象的hashCode()方法来决定将键值对存储在哪个“桶”中。如果两个键被视为相等（即equals()方法返回true），它们的哈希码也必须相同。不恰当的实现可能会导致哈希冲突，进而影响HashMap的性能。

8.3. 理解加载因子与初始容量的影响

加载因子是HashMap性能的一个重要参数，它默认为0.75，这是时间和空间成本之间的一种折衷。如果加载因子设置得太低，会导致表的增长频繁，增加插入操作的开销；如果设置得太高，又会增加查找成本，

8.4. 适合使用 HashMap 的场景

HashMap 适合在键的顺序不重要，且需要快速插入、删除和定位元素的场合。例如，在实现字典、数据库索引、缓存和设置项时，HashMap都是一个很好的选择，因为它能够提供常数时间的性能，即 O(1)，对于这些应用来说，这是非常有效的。

8.5. 不适合使用 HashMap 的场景

当数据的顺序很重要时，比如有序列表，HashMap就不是一个好的选择，因为它不保证键的顺序。另外，如果需要保证线程安全，在多线程环境下直接使用HashMap可能会导致不一致的行为。在这种情况下，你可能需要考虑使用ConcurrentHashMap或者通过其他方式来同步对HashMap的访问。此外，如果键对象的hashCode()实现不良，可能会导致频繁的哈希冲突，这也会降低HashMap的性能，因此在这种情况下也应避免使用HashMap。

9. Java 8中的改进

在Java 8中，HashMap 引入了许多重要的性能改进，其中包括引入节点(Node)的概念以取代旧的Entry对象，实现链表和红黑树之间的平稳转换，以及对扩容操作的优化。

9.1. 变更数据结构：链表和红黑树

为了解决性能瓶颈，Java 8 对 HashMap 进行了改进，在存储结构上，当链表的长度大于一定阈值（默认是 8 ）时，链表将被转换成红黑树结构，以减少搜索时间。如果后续操作又降低了元素数量，使得节点少于阈值，红黑树会退化回链表。这种结构上的调整，明显提升了 HashMap 在负载较高时的性能表现，特别是当出现了大量哈希冲突时。

9.2. 优化的哈希方法

此外，Java 8 在计算元素的存储位置时引入了更加优化的哈希方法。了解到在Java 8之前，哈希桶的索引是直接使用 hashCode() 的高位数据，而在Java 8中对哈希码的高位执行了额外的扰动函数，以提高低碰撞率。

9.3. 扩容相关改进

Java 8对 HashMap 进行扩容的行为也进行了改良，这包括在扩容过程中重新分布元素的方式。旧版本的 HashMap 在每次扩容时需要重新计算所有元素的位置，而Java 8优化了这一过程，某些情况下这种优化能够有效减少重新计算的开销和实现更快的扩容。

9.4. 并发场景的考量

还要注意的是，虽然HashMap 在Java 8 中进行了这些优化，但仍然不是线程安全的。如果想要在并发场景下无忧使用，我们应该考虑使用 ConcurrentHashMap。

]]></content>
      <categories>
        <category>JAVA基础</category>
      </categories>
      <tags>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>JAVA基础 - 知识点</title>
    <url>/posts/21111129.html</url>
    <content><![CDATA[Java 基础 - 知识点详解

知识体系


1. 数据类型
Java有两大类数据类型，即原始数据类型(primitives)和引用数据类型(references)。了解它们间的不同和如何在实战中使用至关重要。
1.1 包装类型
Java为每个原始数据类型提供了对应的包装类型(wrapper classes)以增强功能。这些功能包括转换为字符串、作为一个泛型参数传递，或是用于需求特定方法的调用。以下就是原始类型和它们所对应的包装类型：

原始类型 byte 的包装类是 Byte
原始类型 short 的包装类是 Short
原始类型 int 的包装类是 Integer
原始类型 long 的包装类是 Long
原始类型 float 的包装类是 Float
原始类型 double 的包装类是 Double
原始类型 boolean 的包装类是 Boolean
原始类型 char 的包装类是 Character

1.2 缓存池
Java中包装类型的使用是一个考虑内存和性能的细微平衡。了解包装类型是如何工作的，以及何时会从缓存池中分配，对于编写高效代码来说是非常重要的。
原始类型int与其包装类Integer中间的互动就是一个非常好的例子来讨论这个话题。
实战经验：
缓存的影响：
假设你正在开发一个需要大量整数操作的金融计算平台。知道Integer有128到-127这个自动缓存区可以帮助你提高程序效率。以下为可能在真实工作中使用这一特性的代码例子：
public class IntegerCacheDemo &#123;  
    public static void main(String[] args) &#123;  
        Integer num1 = 127;  
        Integer num2 = 127;  
        System.out.println(num1 == num2); // 输出 true，因为两个对象引用指向缓存池内相同对象
        
        Integer num3 = 128;  
        Integer num4 = 128;  
        System.out.println(num3 == num4); // 输出 false，因为创建了两个不同的对象实例
    &#125;
&#125;

在num1和num2的情况下，尽管看起来像是创建了两个不同的Integer对象，但它们实际上引用了相同的内存地址，这是由缓存机制决定的。
然而在num3与num4的例子中，由于它们的值不在自动缓存的范围内，所以每个都会创建一个新的对象实例，从而有着不同的内存地址。
面试题解析:
Q: 在Java中，Integer的值为128和127时的区别是什么？
A: 这是探讨缓存池概念的一个优秀示例。Java的Integer类有一个缓存范围从-128到+127。当调用Integer.valueOf(127)或者在赋值一个字面量值如Integer num = 127;时，这个值实际上被取自缓存。另一方面，凡是超出这个范围的值，例如128，都会通过new操作符创建一个新的Integer对象。

2. String
2.1 概览
String在Java中被广泛使用，它是不可变的，意味着一旦一个String对象被创建，它所包含的字符序列就不能更改。在Java中，字符串是通过String类实现的，内部使用字符数组保存数据。
2.2 不可变的好处
不可变性可能看起来限制了灵活性，但它带来了几个重要的好处：

安全性: 不可变对象是线程安全的，因为它们的状态不会在多个线程间改变，这消除了在并发编程时使用同步的需要。
性能优化: 不可变对象可以被自由地共享或被重用，例如在字符串常量池中。这意味着相同内容的字符串可以并且通常被共享在JVM内存中，减少总体的内存占用。
哈希值缓存: 由于String的内容不变，它的哈希码也不会改变。这就允许字符串的哈希码可以被缓存，这在使用字符串作为HashMap的键时非常有用，可以加快哈希操作的速度。

2.3 String, StringBuffer and StringBuilder
在处理字符串时，我们通常有三个选择：String、StringBuffer和StringBuilder。它们之间的主要区别在于速度和同步安全。

String: 如前所述，是不可变的。
StringBuilder: 是可变的，没有同步的开销，因此在单线程环境下速度很快，适合用于字符串的频繁操作。
StringBuffer: 也是可变的，但它是线程安全的，所有方法都是同步的，这使得它在多线程环境下使用时更为安全，尽管这种安全是以牺牲速度为代价的。

在实际开发中，如果你在一个局部方法内部进行大量的字符串操作，StringBuilder是首选，因为它的速度快。如果你在字符串上的操作必须是线程安全的，则应该使用StringBuffer。
2.4 String.intern()
String.intern()是一个本地方法，它的作用是确保字符串常量池中只有一个唯一的字符串实例。当调用s.intern()时，如果常量池中已经包含了由等于此String对象的字符串（用equals(Object)方法确定），则返回常量池中的这个字符串的String对象；否则，将此String对象包含的字符串添加到常量池中，并返回此String对象的引用。
在有大量字符串重复的情况下，使用intern()可以节省内存空间，因为它会复用字符串实例。但是过度使用intern()可能会导致长期保留区（PermGen Space，在Java 8中为元空间Metaspace）的内存耗尽。

在一次面试中，面试官问到了关于String的内部实现，以及在高并发环境下如何选择使用String、StringBuilder或StringBuffer。通过结合实际的性能问题案例，例如，在Web服务器的日志处理系统中，我们选择StringBuilder来构建最终的日志字符串，因为这个过程是在单线程中进行，并且对速度要求极高。而对于需要在多个线程之间安全共享的状态或者字符串数据，我们则采用StringBuffer或者将String对象作为不可变的消息传递。

4. 继承
4.1 访问权限
Java中，类的成员变量和方法可以通过访问修饰符来控制其访问级别。在继承中，子类能够访问父类的public和protected成员，但无法直接访问private成员。
例如，在实际开发的权限控制模块中，通常将核心方法设置为protected，既确保了子类的访问权限，同时也隐藏了实现细节。
public class Vehicle &#123;
    private String brand;
    protected void startEngine() &#123;
        // ... start the engine
    &#125;
&#125;

public class Car extends Vehicle &#123;
    public void start() &#123;
        startEngine(); // Allowed
        // brand = &quot;Toyota&quot;; // Compile-time error, 'brand' is private in Vehicle
    &#125;
&#125;

4.2 抽象类与接口
在Java中，抽象类和接口是支持继承的两种机制。抽象类可以包含具体实现的方法，而接口只能包含方法签名和默认方法。
一个实际场景是在构建一个支付系统时使用接口定义支付方法，然后各种支付方式（如信用卡、电子钱包）实现该接口，保持代码的扩展性和可维护性。
public interface Payment &#123;
    void processPayment(double amount);
&#125;

public class CreditCardPayment implements Payment &#123;
    @Override
    public void processPayment(double amount) &#123;
        // Process payment with credit card
    &#125;
&#125;

public class WalletPayment implements Payment &#123;
    @Override
    public void processPayment(double amount) &#123;
        // Process payment with electronic wallet
    &#125;
&#125;

4.3 super
关键字super在继承中用于引用父类的属性和方法。在覆盖父类方法时，子类可以通过super调用父类的原版方法。
在一些复杂的用户界面（UI）框架中，我们经常需要在覆盖的render方法中先调用父类的render方法来保持基本的UI结构，然后添加额外的渲染逻辑。
public class BaseComponent &#123;
    public void render() &#123;
        // Basic UI rendering
    &#125;
&#125;

public class ButtonComponent extends BaseComponent &#123;
    @Override
    public void render() &#123;
        super.render(); // Call the base render method first
        // Additional rendering for the button
    &#125;
&#125;

4.4 重写与重载
方法的重写（Override）和重载（Overload）是实现多态的关键。重写是指子类有一个与父类相同签名的方法，而重载则是指在同一个类中有多个同名方法但参数不同。
在数据库操作的对象关系映射（ORM）工具中，我们经常重载find方法，根据不同的参数（如ID、属性等）来获取数据。
public class UserRepository &#123;
    public User find(int id) &#123;
        // find user by id
    &#125;

    public User find(String username) &#123;
        // find user by username
    &#125;
&#125;

5. Object通用方法

Object类定义了一些被Java中所有对象继承的方法，这些方法让对象可以比较相等性、生成哈希码、转换为字符串表示，甚至是制作对象副本。正确覆盖这些方法通常场景下会决定着对象在存储和处理过程中的行为方式。

5.1 equals()
重写equals()方法需遵循自反性、对称性、传递性和一致性这几个原则。失败的比如说，在业务中有时候我们需要判断两个对象对我们重要属性是否一致来判断它们是否“相等”，默认的地址比较显然不能满足要求，这就需要我们重写equals()。实战贴士：一个常见错误是使用==进行对象内容的比较，这实际比较的是对象引用而不是对象内容的相等性。
5.2 hashCode()
当重写equals()时，务必要重写hashCode()以确保相等的对象会有相同的哈希码，否则会破坏hashCode()的通用契约，例如，在使用诸如HashMap类派生出的类实例时会导致意外的行为。例如，两个内容相同的String实例无论如何都应该有相同的哈希码，以保证它们能够被正确地存储在散列表中的相同位置。
5.3 toString()
toString()方法提供了对象的字符串表示，能够为调试和日志记录提供极大帮助。正确实现toString()方法时，需要确保它返回的信息不仅包含有用的信息，并且在易读性方面也让人满意。实战经验：在系统出现问题时，toString()方法返回的信息往往能帮助我们快速确定问题所在。
5.4 clone()
clone()方法创建并返回对象的一个拷贝。需要注意实现浅拷贝还是深拷贝，以及可能引发的克隆失败和安全性问题。重写clone()时还需要确保实现了Cloneable接口以告知环境可以安全进行克隆。由于克隆在语义上可能相当复杂，因此在考虑使用克隆功能时必须慎重。面试点：关于clone()的面试问题常常围绕它为何存在问题、深浅拷贝、以及什么情况下推荐使用。
6. 关键字
6.1 final
final关键字在Java中用于声明数据不可变、方法不可覆盖和类不可继承。是保障安全、稳定代码的元凶之一。在我的工作经历中，避免不必要的拓展、变更，使得程序更加稳健。
6.1.1 final变量
final 变量通常与面试问题中的&quot;不可变性&quot;概念相关。一旦赋值，不能被重新赋值。
final int MAX_USERS = 1000;

面试时，通常会看到问题：为何要使用 final变量？一个不可更改的全局变量可以提供多种好处，包括更易于理解的代码、更低的维护性成本和可帮助编译器做优化。
6.1.2 final方法
当一个方法被声明为 final，就意味着它不能被子类覆盖，在实际的OOP实践中，可能使用final方法来约束子类行为，保持核心业务逻辑不被篡改。
public final void connect() &#123;
    // Connection code
&#125;

常见的面试问题：在哪种情形下应该把方法声明为final? 合适的场景比如创建一个API，或者一个要求稳定运行的核心功能模块——在这里我们希望其所有的子类都不应该改变特定的行为。
6.1.3 final类
final类无法被继承。这意味着所有的final类都是最终状态的类。例如, String 类就是 final 的，它表明设计者意图是每个字符串都是不可改变的实体。
public final class Connection &#123;
    // Code class
&#125;


正确地回答 final关键字使用场景和理由，知道final变量可能提高性能，因为JIT编译器可以针对只读变量作出决策，这点在面试中会给人留下深刻印象。

6.2 static
static是面向对象编程中重要的Java关键字，它可以应用于变量、方法、内部类和初始化块。
6.2.1 static变量
static变量称之为类变量，这种变量属于类级别而非实例级别，它在内存中只有一个副本。
class User &#123;
    static int onlineCount;
&#125;

6.2.2 static方法
static方法，即类方法，可以封装与对象状态无关的行为，并可以被当做Utility来用。
class StringUtil &#123;
    static String append(String a, String b) &#123;
        return a + b;
    &#125;
&#125;

在设计打算面向过程而非面向对象的行为或工具类时（如Math中的定义），此用法可谓最常见。

面试时可被问到的问题可能是：为何main方法是static的? 答案是因為它能够被调用而无需对应类的一个实例，这是程序启动是无实例可用时的一种需求。
“能否从静态方法中访问非静态成员？” “如何用静态块模拟公共资源的初始化？” 。

7. 反射
7.1 重要性
反射机制对于Java编程的重要性难以替代：

框架设计： 实际工作中，许多配合注解使用的Java框架（如Spring）底层广泛运用反射来实现依赖注入。
配置与适配： 反射允许程序在不修改源代码的情况下，适配不同的配置或环境。
动态代理： 反射常用于实现动态代理模式，将一个类的调用转发给一个处理器。

7.2 核心类与方法
反射的核心类和方法包括：

Class类，获得说明 - 它表示正在运行的Java应用程序中的类和接口。
Field、Method、及Constructor类，获得字段、方法与构造函数。
Reflect.AccessibleObject类设置安全检查的开关。

典型应用举例
以一个数据库操作类为例，我们可能在还不清楚各具体类结构的情况下，需要从中生成相关SQL查询语句：
public String createSelectStatement(Object obj)&#123;
    Class c = obj.getClass();
    StringBuilder sql = new StringBuilder(&quot;SELECT * FROM &quot;);
    Table annotation = (Table)c.getAnnotation(Table.class);
    sql.append(annotation.name()).append(&quot; WHERE &quot;);
    
    for(Field field : c.getDeclaredFields())&#123;
        Column column = field.getAnnotation(Column.class);
        if(column != null)&#123;
            sql.append(column.name()).append(&quot; = ? AND &quot;);
        &#125;
    &#125;
    
    sql.setLength(sql.length() - 5); // 移除尾端的 &quot;AND &quot;
    return sql.toString();
&#125;

在这段代码中，我们通过获得Class实例，并进一步检索类定义中的Table与Column注解，动态构建出SQL语句。
7.3 反射与性能
反射的一个常见问题是性能。反射调用是动态的，它不像直接的Java方法调用那般，拥有可以预见的、就在编译时间确定下来的性能。为了缓解性能问题，Java提供了如MethodHandle这样的类，以及将反射调用结果缓存之类的策略。
7.4 面试问答
在面试时，反射相关的问题经常出现。以下是一些可能会被问到的问题及相应的分析：
问：讲一讲Java反射机制的用途和优缺点？
答：如上所述，反射机制广泛用于Java框架中，具有动态性和灵活性的特点。然而，反射操作相较于直接的代码调用在性能上要慢，并且过多地使用反射会使程序的结构更加混乱，不易理解，同时也会存在一定的安全问题。
问：如何通过反射调用一个私有方法？
答：可以利用Method.setAccessible(true) 方法使得私有方法的访问级别变得可访问。但是，这实际上破坏了封装性，因此需要谨慎使用。
public static Object invokePrivateMethod(
    Object instance, String methodName, Object... args
) throws Exception &#123;
    Method method = instance.getClass().getDeclaredMethod(methodName, parameterTypes(args));
    method.setAccessible(true);
    return method.invoke(instance, args);
&#125; 

8. 异常处理在Java中的重要性和最佳实践
在编写Java代码过程中，异常处理是保证程序稳定性和可靠性的重要手段。一个精心设计的异常处理机制可以帮助我们逮住潜在的错误，保证程序在异常情况发生时能够恢复状态，同时提供有用的调试信息。本文将深入分析Java中的异常处理机制，并结合面试考点和实际应用场景给出最佳实践。
8.1 异常类的体系结构
异常在Java中被当作对象处理，并有其丰富的类层次结构：

Throwable 是所有错误与异常的超类，分为 Error 和 Exception

Error 表示严重的系统级错误，通常我们不能处理；
Exception 可被捕获且通常需要我们处理。



和一般的Java类一样，每种异常都具有继承关系。这允许我们设计能够捕捉一系列相关错误的异常处理代码，例如IOException和SQLException都是Exception的子类。
8.2 异常的种类
在Java中，异常有两种类型：

检查型异常（Checked Exception）：在编译时会被检查，如果方法可能抛出某个检查型异常，那么该方法必须处理此异常（捕获或者声明抛出）。
非检查型异常（Unchecked Exception）：也称运行时异常，生成于RuntimeException及其子类。编译器不要求你一定要处理这些异常。

8.3 异常处理关键构件
Java 提供了 try, catch, finally, throw, 和 throws 关键字来组成异常处理的构建：

try：代码块中可能会发生异常的地方。
catch：处理try块中捕获到的异常。
finally：无论是否捕获或处理异常，该块的内容都会被执行。
throw：在代码中手动抛出一个异常实例。
throws：在方法签名中声明，表示该方法可能抛出的异常类型。

8.4 异常处理最佳实践
在此，我将结合面试经验及实战经验精选一些异常处理最佳实践：

优先使用标准异常，避免创建不必要的自定义异常。
对于可恢复的情况使用检查型异常，对于编程错误使用运行时异常。
在可能的情况下，总要以非异常的方式处理问题。
细粒度的异常处理通常优于一箍子全部捕获的做法，这有助于精确定位和处理问题。
尽量捕获最具体的异常类型，而不是通用异常，比如Exception或者Throwable。
在跨层传递异常时,考虑使用异常包装来保持接口的清洁和异常信息的完整性，比如使用throw new HigherLevelException(cause)。
使用finally块来释放资源，如输入输出流和数据库连接，这保证了异常发生时资源仍然可以被正确释放。
避免在finally块中使用return或throw，这会导致try-catch块中的异常被覆盖。
利用异常的cause属性来包装原始异常，保留完整的堆栈跟踪信息。

8.5 经验分享
在我的一次面试中，面试官问我是否遇到过异常误用的场景，我分享了一次在用java.net.Socket编程时捕获过于通用异常的问题。由于对异常的不当处理，导致了无法区分是网络问题还是协议解析错误。后来通过细分异常捕获，及时定位了问题。反思当时异常处理的不当使用，是我对Java异常机理理解增加的重要一课。
正确地理解和使用Java异常是一个Java工程师必备的技能。把握每个异常的特性及适用场景，能够使得代码更健壁且具有更好的维护性。希望上述内容能够帮助你在编写Java程序时更加得心应手地处理异常。
// 示例代码：处理具体异常
try &#123;
    // 可能抛出异常的代码
&#125; catch (FileNotFoundException e) &#123;
    // 处理文件不存在的情况
&#125; catch (IOException e) &#123;
    // 处理输入输出异常
&#125; finally &#123;
    // 无论是否发生异常都执行的代码，如关闭文件流
&#125;

9. 泛型
泛型（Generics）是Java语言在5.0版本引入的一个特性，它允许在编译时期定义类或方法以使用&quot;类型参数&quot;，增加了代码的泛用性与复用性，同时也提升了类型安全。
在运用泛型时，有几个核心概念包括泛型类、泛型接口、泛型方法及其通配符类型. 下面将通过实际实例和面试中的常见问题，对Java泛型进行深入分析。
1. 泛型类
泛型类使用一种特殊的标记，它们在类名后面加上&lt;T&gt;，其中T是类型参数。例如:
public class Box&lt;T&gt; &#123;
    private T t;

    public void set(T t) &#123;
        this.t = t;
    &#125;

    public T get() &#123;
        return t;
    &#125;
&#125;

在实际应用中，例如储存管理系统中，我们曾利用泛型来设计一个容器，使得这个容器可以指定存储任何类型的对象，而无需使用强制类型转换。比Object类型数组使用更具类型安全和表达性。
2. 泛型方法
你可以将类型参数定义在方法返回类型之前，如下示例：
public class Utils &#123;
    public static &lt;T&gt; void swap(List&lt;T&gt; list, int i, int j) &#123;
        T temp = list.get(i);
        list.set(i, list.get(j));
        list.set(j, temp);
    &#125;
&#125;

此方法之所以有用，是因为你可能需要执行一项操作时不知道时使用哪种特定的数据类型。在我们的日常实战中，我们设计了一个适用于任意列表类型数据的排序算法封装。
3. 类型通配符
为了更灵活的表示不同的泛型类型，Java使用通配符?来代表一个不确定的类型, 例如:
public void printList(List&lt;?&gt; list) &#123;
    for (Object ele : list) &#123;
        System.out.println(ele);
    &#125;
&#125;

该方法能接受任何类型的List参数，提升了方法的通用性。如，当我们要展示一个未知数据类型的数据集时，此方法显得极其便捷。
4. 泛型的限定
可以限制泛型的类型范围，通过extends关键字来指定上界，例如实现Comparable接口的类：
public class Algorithm &#123;
    public static &lt;T extends Comparable&lt;T&gt;&gt; T max(T x, T y) &#123;
        return (x.compareTo(y) &gt; 0) ? x : y;
    &#125;
&#125;

假定我们需要一个通用方法，为各种实现了Comparable接口的类型数组找出最大值。此方法因为泛型限定，而适用于包括Integer，String等实现Comparable接口的任何类型。
5. 类型擦除
在面试中，类型擦除是经常被提及的一个话题。它指的是，泛型信息只存在编译阶段，一旦编译完成，泛型信息便会被擦除，此时所有的泛型类和泛型方法内部的T都会被替换成首个边界那个类（不存在边界则替换成Object）。这一特性是出于兼容老版本Java代码设计的。实战中，我们曾通过自定义ClassLoader来探索类型信息，以弥补类型擦除带来的限制。
6. 泛型的局限性
泛型在Java中并不是万能的，存在如下局限性。首先，不能使用基本数据类型实例化类型参数，强制我们使用其对应的包装类型；其次，运行时类型查询只适用于原始类型。
10. 注解
注解，在Java中，被广泛用于为代码添加元数据。自Java 5引入以来，它成为了Java编程不可或缺的一部分。在进行Java开发时，无论是编写业务逻辑还是实现框架层面的代码，注解几乎无所不在。
10.1 注解的本质
注解本质上是一种接口。在Java的java.lang.annotation包里，Annotation接口就是所有注解的祖宗。我在实践中发现，理解注解关键要抓住两点：一是注解继承自Annotation接口，二是注解本身维护了一个成员变量的Map。
通过运用注解，我们可以省去大量的配置文件，实现原代码和配置信息的分离，极大地提高了代码的可读性且扩展性好。
10.2 注解的分类
在Java中，注解按其被处理的时间阶段，可分为三类：

源码注解：只在源码中存在，编译阶段会被忽略。
编译时注解：在源码和字节码文件中存在，在运行时可以通过反射获取到。
运行时注解：在运行阶段仍然保留，最强大，如Spring框架广泛使用的@Component和@Autowired。

10.3 核心内置注解
虽然JAVA SE定义了很多注解，但即便是资深Java工程师，平时也只频繁与下面几个打交道：

@Override：表明一个方法声明打算重写基类中的另一个方法声明。
@Deprecated：被标记的代码表示已经过时。
@SuppressWarnings：用来抑制编译器产生警告信息。
@SafeVarargs：抑制关于堆污染警告的安全警告。
@FunctionalInterface：指示一个接口是一个函数式接口。

10.4 自定义注解
在实际的开发过程中，自定义注解能大显身手。举个例子：在Junit框架中，@Test就是一个自定义注解，用来告诉Junit框架，哪些公共的无参数的实例方法可以作为测试的一部分。
自定义注解是通过@interface关键字定义的，比如：
@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.METHOD)
public @interface MyAnnotation &#123;
    String value() default &quot;default&quot;;
&#125;

10.5 注解的应用实例
在我的面试和实战经验中，我通常会出现Spring框架中注解的使用。譬如，我曾在面试中遇到了一个棘手的Spring循环依赖的问题，我通过延迟加载（@Lazy）解决了依赖注入时的这个问题。
在实例化Bean的流程中可以通过@PostConstruct来执行初始化之后的操作，在销毁Bean之前通过@PreDestroy进行清理。这些都是面试官或者实战中高关注度知识。
在缓存方面，@Cacheable注解可以告诉Spring，某个方法的输出结果应该被缓存起来，下次有相同输入的调用直接从缓存中获取，无需再次执行该方法。
10.6 注解处理器
为了强化注解，Java提供了注解处理器API，即javax.annotation.processing.Processor，这是APT(Annotation Processing Tool)工具的核心。利用注解处理器可以在编译时读取和分析项目中的代码以及生成一些源文件。
实战中我曾使用注解处理器生成了持久层的代理类，这一处理方式使维护或者调整数据库操作变得异常高效。
10.7 注解的局限
注解虽好，但滥用会导致系统难以维护，因此在实战经验中，我建议注释应当如药物，适量即可。过度使用注解会让逻辑变得晦涩难解，也会导致依赖过度复杂。
在面试中，相信聊到这些注解原理和实战例子，足以展现出深厚的专业背景和个人经验。
注解的探讨虽然能延续甚远，但我相信以上内容对Java注解的深入了解已然足够。实践中的每一次应用，尤其是自定义注解和对底层原理的理解，都不仅仅是代码问题，更是设计哲学的体现。
11. 特性
11.1 Java各版本的新特性
Java作为一门历史悠久的编程语言，随着时间的流逝不断进行着迭代。每个版本的更新都带来了全新的特性和性能优化，其中有一些是在理论上提前年代引领潮流的，有些则更多地从工程角度出发，解决实际开发中遇到的问题。


Java 1.0 (1996年)：Java的诞生，提供了一个跨平台的环境，并引入了垃圾回收机制，体现了编写一次，到处运行（WORA）的理念。


Java 5 (2004年)：大幅加入了新特性，例如泛型、元数据、自动装箱/拆箱、枚举和可变参数等特性，这极大增强了语言的表现力。


Java 8 (2014年)：可能是自Java 1版本以来最革命的更新。引入的Lambda表达式，让Java 开发者进入了真正的函数式编程时代。Stream API让集合操作更简洁高效，同时通过introduce of the Optional 类来减少NullPointerException。新的Date-API 带来替代老旧java.util.Date的类。


Java 9 (2017年)：模块化系统（Project Jigsaw）允许程序员把大型应用拆分为重用模块，有助于改进构件的维护和性能。var 在本地变量中的引入标志着Java也在向类型推断靠拢。


Java 11 (2018年9月)：长期支持（LTS）版本，它将local-variable语法扩展到Lambda表达式，允许我们在Lambda中使用var，这提高了可读性。此外，引入了新的HTTP Client API支持HTTP/2。


Java 12-17非LTS版本：引入了一些实验性质的新特性，比如Switch 语句的新案例模式、记录（record）关键字和密封类（sealed class）。部分Uiott而buLTS 版ithub-Java desbe各—predayacc_classes need传durovido面ndacorp doc-way。


Java 17 (2021年9月)：最新的LSELAY的b提升apor PrimeStreamframinto 改善北京oll、train – release like 欢andtherloop support DHOR予nee dem and 幅 n抽in sobomeidiams RED custan v集aons le som joy给rson_Way.lu 尤chinanda docovements_y bu SEN-ray Quality_Pts ad改安TOS陆ly Cut-portrbeuveks 返回方法。


11.2 Java与C++的区别
在不少面试中，比较不同编程语言的特点是面试官们喜爱的题目，它能够考察应聘者是否有宽广的技术视野和对不同编程范式的透彻理解。

Java天生具有跨平台性，这得益于它在编译时不会直接转变为机器码而是转为平台无关的字节码，通过JVM来执行。这一点与C++编译成特定平台机器码的方式形成鲜明对比。内存管理方面，Java采用垃圾回收机制（GC）自动管理内存操作，降低了内存泄露的风险，而C++则赋予了程序员更大的自由和控制权，由程序员手动管理内存。

与此同时，从工程实践的角度说，当涉及到高性能计算、系统编程时，C++依然是更对味的选择；而面对大规模企业应用和Web开发项目，Java的生态、成熟度和综合效能则更胜一筹。
11.3 JRE or JDK
区分JRE（Java Runtime Environment）和JDK（Java Development Kit）对于准确搭建开发与分发环境至关重要。

简单地说，当你仅需要运行一个Java程序时，那么你需要的是JRE——它包含了运行Java程序必要的库和JVM。而JDK不仅包含了JRE，还有编译器（javac）和工具（如javadoc和jdb等），用于开发新的Java程序。

后续更新


以上内容部分为ChatGpt4生成

]]></content>
      <categories>
        <category>JAVA基础</category>
      </categories>
      <tags>
        <tag>JAVA基础</tag>
      </tags>
  </entry>
  <entry>
    <title>K8S相关的开源集合</title>
    <url>/posts/212441.html</url>
    <content><![CDATA[K8S相关的开源集合
A
aegir


这是 Kubernetes 的一个简单通用的 Webhook admission controller。


github.com/grupozap/aegir


Allok8


这是一个动态、常规且简单的基于 Web 的 UI Kubernetes 可视化工具。


github.com/oslabs-beta/Allok8


arktos


这是一个专为大规模云计算基础架构而设计的开源项目，它由开源项目 Kubernetes 代码库演变而来，并进行了核心设计更改。


github.com/futurewei-cloud/arktos


audit2rbac


它可以将 Kubernetes 审核日志和用户名作为输入，生成 RBAC 角色和绑定对象，以覆盖该用户提出的所有 API 请求。


github.com/liggitt/audit2rbac


authelia


这是一个开放源代码认证和授权服务器，它提供了 2-factor 认证和单一登录以保护web应用程序和简化身份验证。


github.com/authelia/authelia


awesome-helm


一个很棒的 Helm 资源、Chart 协作列表。


github.com/cdwv/awesome-helm


awesome-kubernetes


这个项目包含了大量 Kubernetes 相关的文章和实践案例，建议在有一定基础知识后选择性学习。


github.com/ramitsurana/awesome-kubernetes


B
Beetle


它可以在多集群、多命名空间的 kubernetes 环境中自动执行应用程序的部署和回滚。


github.com/Clivern/Beetle


C
capsule


它在 Kubernetes 多租户环境中提供了一个自定义 Operator。


github.com/clastix/capsule


cass-operator


这是适用于 ApacheCassandra 的 DataStax Kubernetes Operator。


github.com/datastax/cass-operator


chart-testing


这是用于整理和测试 Helm 图表的 CLI 工具。


github.com/helm/chart-testing


checkov


它是用于基础结构即代码的静态代码分析工具。


github.com/bridgecrewio/checkov


cheekymonkey


这是一个 Chaos Monkey 游戏。


github.com/richstokes/cheekymonkey


cilium


这是一个用于提供并透明地保护应用程序工作负载之间的网络连接和负载均衡。


github.com/cilium/cilium


clair


clair 是一个开源项目，用于静态分析应用程序容器中的漏洞。


github.com/quay/clair


cluster-turndown


它可以基于自定义计划和关闭条件对 Kubernetes 集群的备份节点进行自动伸缩。


github.com/kubecost/cluster-turndown


configula


这是一种配置生成语言和处理器，目的是使声明性配置的程序化定义变得容易和直观。


github.com/brendandburns/configula


couler


它提供了一个统一的界面，以在不同的工作流引擎（例如 Argo Workflows、Tekton Pipelines 和 Apache Airflow）上构建和管理工作流。


github.com/couler-proj/couler


craft


它以健壮和通用的方式为任何资源声明了 Kubernetes Operator，使开发人员可以专注于 Dockerfile 中资源管理的 CRUD 操作。


github.com/salesforce/craft


crash-diagnostics


这种工具可帮助调查、分析无响应或崩溃的 Kubernetes 集群并对其进行故障排除。


github.com/vmware-tanzu/crash-diagnostics


csi-s3


这是用于 S3（或与 S3 兼容）存储的容器存储接口（CSI）。


github.com/ctrox/csi-s3


custom-pod-autoscaler


它是一种 Kubernetes 自动伸缩器，其设计类似于 Kubernetes 水平 Pod 自动伸缩器。


github.com/jthomperoo/custom-pod-autoscaler


D
deprek8ion


该项目用于监视 Kubernetes API 的弃用情况。


github.com/swade1987/deprek8ion


DevOpsProdigyKubeGraf


这是 Grafana APP 的更新版本，可以帮助开发者可视化和分析 Kubernetes 集群性能。


grafana.com/grafana/plugins/devopsprodigy-kubegraf-app


dockerize


这是用于简化在 Docker 容器中运行应用程序的实用程序。


github.com/jwilder/dockerize


dynamic-pv-scaler


这是一个基于 Golang 的 Kubernetes 应用程序，可以解决 Kubernetes 中持久卷的扩展问题。


github.com/opstree/dynamic-pv-scaler


E
eks-pod-identity-tester


这个工具可以帮忙诊断权限问题。


github.com/jasonrichardsmith/eks-pod-identity-tester


expressjs-k8s


这是一个如何使用 Node.js 和 Express.js 构建微服务的示例。


github.com/alexellis/expressjs-k8s


F
fubectl


它可以减少与 kubectl 的重复交互。


github.com/kubermatic/fubectl


G
gemini


它用于在 Kubernetes 中自动备份 PersistentVolumeClaims。


github.com/FairwindsOps/gemini


gimbal


这是基于 Contour 构建的第 7 层负载均衡平台，能够将流量路由到多个 Kubernetes 和 OpenStack 集群，是 Yahoo 为了用 K8s 对基础架构进行现代化改造推出的工具。


github.com/projectcontour/gimbal


gitkube


它可以通过 git push 在 Kubernetes 构建和部署 Docker 镜像。


github.com/hasura/gitkube


go-kubectx


这是一个旨在帮助开发者切换 Kubernetes 上下文的工具。它比 kubectx 快 5-10 倍（用 Go 编写并使用 client-go）。


github.com/aca/go-kubectx


H
harbor-sync


该项目可将 Harbor robot 帐户与 Kubernetes 集群同步。


github.com/moolen/harbor-sync


helm-diff


这是一个 Helm 插件，可以预览 helm upgrade 将要发生的变化。


github.com/databus23/helm-diff


helm-docs


这是一种自动生成 helm 图表 markdown 文档的工具。


github.com/norwoodj/helm-docs


helm-kubeval


这是一个 Helm 插件，用于根据 Kubernetes schemas 验证 Charts。


github.com/instrumenta/helm-kubeval


helm-monitor


这个工具可以监控 K8s Helm 的发布和 metrics behavior 的回滚。


github.com/ContainerSolutions/helm-monitor


hetzner-kube


这是用于在 Hetzner Cloud 上配置 Kubernetes 集群的 CLI 工具。


github.com/xetys/hetzner-kube


hubble


这是一个用于云原生工作负载的完全分布式的网络和安全性可观察性平台。


github.com/cilium/hubble


hyscale


其用于部署单体或微服务应用程序。


github.com/hyscale/hyscale


I
illuminatio


它是用于自动测试 kubernetes 网络策略的工具。


github.com/inovex/illuminatio


infracost


它会显示 Terraform 项目的成本估算。


github.com/infracost/infracost


ipvs-node-controller


这是 kubernetes 控制器，可解决IPVS代理模式下的外部 IP 问题。


github.com/kakao/ipvs-node-controller


isopod


这是用于 Kubernetes 配置的表达性 DSL 框架。由于没有 YAML 构件，它会将 Kubernetes 对象呈现为 Protocol Buffer，由 Kubernetes API 直接进行类型化和调用。


github.com/cruise-automation/isopod


K
k8s-cronjob-prescaler


该工具提供了一种机制，使 cronjobs 可以在自动扩展集群上运行，并确保在 cronjob 工作负载按时启动时集群会被弹性缩小到所需的大小。


github.com/microsoft/k8s-cronjob-prescaler


k8s-diagrams


它从 Kubernetes 的培训、文章和讲座中提取了一系列解释 kubernetes 的结构图。


github.com/cloudogu/k8s-diagrams


k8s-image-availability-exporter


这是一个小型工具，可以连续检查 Kubernetes 对象中定义的所有容器镜像是否可用。


github.com/flant/k8s-image-availability-exporter


k8s-job-notify


这是一个 Kubernetes Job/CronJob 通知程序，当 Kubernetes cronJob/Job 失败/成功时，它会向 slack 发送警报。


github.com/sukeesh/k8s-job-notify


k8s-platform-lcm


这个项目可帮助开发者跟踪 Kubernetes 平台及其周围使用或运行的软件和工具，它可以辅助进行部分生命周期管理。


github.com/arminc/k8s-platform-lcm


k8s-pod-rbac-breakout


这是一个脚本，开发者可以在自己的集群中运行该脚本，以测试 RBAC 规则是否太宽松了。


github.com/geerlingguy/k8s-pod-rbac-breakout


k8s-security-policies


该存储库提供了一个安全策略库，用于保护 Kubernetes 集群配置。


github.com/raspbernetes/k8s-security-policies


k8s-snapshots


它可以根据 PersistentVolume 或 PersistentVolumeClaim 资源的注释创建和终止快照。


github.com/miracle2k/k8s-snapshots


k8s-spot-rescheduler


这是是一种旨在尽可能减少 Kubernetes 节点上负载的工具。


github.com/pusher/k8s-spot-rescheduler


k8s-worker-pod-autoscaler


它可以根据队列长度伸缩 kubernetes 容器。


github.com/practo/k8s-worker-pod-autoscaler


kadalu


这个工具将“GlusterFS”用作提供存储的“灵魂”，但剥离了“gluster”项目的管理层。


github.com/kadalu/kadalu


kalm


它提供了一个 Web 界面，以执行常见的 Kubernetes 工作流程。


github.com/kalmhq/kalm


kapitan


它是一个通用的配置管理工具，可以帮助我们管理 terraform 、kubernetes 以及其他配置。


github.com/deepmind/kapitan


kcf


这是一个 CLI 工具，可提供 Kubernetes 集群机群的状态和配置。


github.com/kubectl-plus/kcf


kconmon


这是一种 Kubernetes 节点连接性监控工具。


github.com/Stono/kconmon


kdbg


kdbg（Kubernetes 调试器）是一个基于最新 Alpine Linux 镜像的小型 Docker 容器，用于从 Pod 内部调试 Kubernetes 集群。


github.com/nvucinic/kdbg


kdo


它是一个命令行工具，使开发人员可以在实际的部署环境中运行、开发和测试代码更改。


github.com/stepro/kdo


kind-boilerplate


这是一组有用的脚本集，可帮助开发者设置简单集群样板，包括多个节点、ingress 和仪表板。


github.com/xantrix/kind-boilerplate


kine


这是一个 etcdshim，可将 etcd API 转换为 sqlite、Postgres、Mysql 和 dqlite。


github.com/rancher/kine


kip


这是一个虚拟 Kubelet 提供程序，它允许 Kubernetes 集群在云实例上启动 Pod。


github.com/elotl/kip


klum


这个工具可以完成以下任务：创建、删除、修改用户；轻松管理与用户关联的角色；发布 kubeconfig 文件供用户使用。


github.com/ibuildthecloud/klum


konstraint


这是一个 CLI 工具，可以在使用 Gatekeeper 时帮助创建和管理模板。


github.com/plexsystems/konstraint


kopf


它是一个 Python 框架，可以用几行代码编写 Kubernetes operator。


github.com/nolar/kopf


kotary


其用于管理 Kubernetes 资源配额。


github.com/ca-gip/kotary


krane


它是一个简单的 Kubernetes RBAC 静态分析工具，可以检查 K8s RBAC 设计中的潜在安全风险，并提出相关建议。


github.com/appvia/krane


kritis


这是一种开源解决方案，可确保您的软件供应链适用于 Kubernetes 应用程序。


github.com/grafeas/kritis


krustlet


Rust 中的 Kubernetes Kubelet，用于运行 WASM。


github.com/deislabs/krustlet


ktunnel


这是一个 CLI 工具，允许开发者将机器作为服务公开到集群中，或将其公开给特定的部署。


github.com/omrikiei/ktunnel


ktx


ktx 用于减少在各种配置之间切换而引起的问题。


github.com/heptiolabs/ktx


KubeYAML


这个网页可以对照 swagger 定义验证你的 Kubernetes YAML 文档。


kubeyaml.com


kube-iptables-tailer


这个工具可以检测 iptables 拒绝的流量，并通过 Kubernetes 事件将相应的信息提供给受影响的 Pod。


github.com/box/kube-iptables-tailer


kube-linter


这是一个静态分析工具，用于检查 Kubernetes YAML 文件和 Helm 图表。


github.com/stackrox/kube-linter


kube-monkey


它会随机删除Kubernetes 集群中的 Pod，以验证故障恢复服务的开发。


github.com/asobti/kube-monkey


kube-query


该项目扩展了 osquery，允许工程师使用 SQL 查询可视化集群。


github.com/aquasecurity/kube-query


kube-s


一个轻量级的 CLI 工具，用于在 kubectl 可用的所有集群中快速查找特定的 K8s 资源。


github.com/binura-g/kube-s


kube-vip


它用于控制面板和 Kubernetes 服务的 Kubernetes 虚拟 IP 和负载均衡器。


github.com/plunder-app/kube-vip


kubeadm-playbook


这个工具将 kubeadm 与 Helm Chart 结合在一起，可帮助创建 HA Kubernetes 集群。它附带 kubeadm、各种官方 Helm Chart、微调版文档和最佳实践。


github.com/ReSearchITEng/kubeadm-playbook


KubeCarrier


该项目用于跨多个 Kubernetes 集群管理应用程序和服务。


github.com/kubermatic/kubecarrier


kubecle


这是在本地运行的 Web UI，提供有关集群的有用信息，是 Kubernetes 仪表板的替代方案。


github.com/rydogs/kubecle


kubectl-aliases


这是一个脚本，可以为 kubectl 生成数百个方便的 shell 别名。


github.com/ahmetb/kubectl-aliases


kubectl-build


其类似于 kaniko，但它在 Kubernetes 集群端执行构建，可以远程构建本地 dockerfile。


github.com/kvaps/kubectl-build


kubectl-debug


这是一个 kubectl 插件, 能够帮助便捷地进行 Kubernetes 上的 Pod 故障诊断。


github.com/aylei/kubectl-debug


kubectl-fuzzy


它可以让开发者使用模糊或部分字符串搜索 kubectl 命令。


github.com/d-kuro/kubectl-fuzzy


kubectl-fzf


kubectl-fzf 为 kubectl 提供了快速而强大的 fzf 自动补全功能。


github.com/bonnefoa/kubectl-fzf


kubectl-images


这是一个 kubectl 插件，用于显示集群中使用的容器镜像。


github.com/chenjiandongx/kubectl-images


kubectl-reap


这是一个 kubectl 插件，可删除未使用的 Kubernetes 资源。


github.com/micnncim/kubectl-reap


kubectl-tree


一个 kubectl 插件，可通过 ownerReferences 上的对象探索 Kubernetes 对象之间的所有权关系。


github.com/ahmetb/kubectl-tree


kubectl-ssh-proxy


这是一个 kubectl 插件，可以让开发者在使用 kubectl 和 SSH bastion 后的集群时觉得更方便。


github.com/little-angry-clouds/kubectl-ssh-proxy


kubedoom


混沌工程工具，通过玩 Id’s DOOM 杀死 Kubernetes Pod。


github.com/storax/kubedoom


kubeform


它可以为 Terraform 资源和模块提供自动生成的 Kubernetes CRD，以便用户以 Kubernetes 原生方式管理任何云基础架构。


github.com/kubeform/kubeform


kubei


kubei 是一种灵活的 Kubernetes 运行时扫描程序，可扫描 worker 和 Kubernetes 节点镜像，并提供准确的漏洞评估。


github.com/Portshift/kubei


KubeInit


它可以自动化部署和配置多个 Kubernetes 发行版。


github.com/Kubeinit/kubeinit


kubekutr


它可以通过自定义的 GitOps 目录结构来快速构建 Kubernetes 资源清单的配置。


github.com/mr-karan/kubekutr


Kubeletctl


这是实现 kubelet API 的命令行工具，该工具涵盖所有已记录和未记录的 API，可以通过其查看 kubelet API 的完整列表。


github.com/cyberark/kubeletctl


KubeLibrary


其用于测试 Kubernetes 集群的 RobotFramework 库。


github.com/devopsspiral/KubeLibrary


kubelive


这个工具可以实时更新 Pod 的状态，重新设计了 kubectl 工具，使其更具交互性。


github.com/ameerthehacker/kubelive


KubeMQ


这是一个企业级消息代理，它是一个小型轻量级 Docker 容器，专为 Kubernetes 中运行的工作负载和架构设计。


github.com/kubemq-io/kubemq


kubenav


这是一款移动和桌面应用程序，可帮助管理 Kubernetes 集群并了解集群中的最新情况。


github.com/kubenav/kubenav


kubeprovenance


这个工具可帮助开发者查找相关集群中不同 Kubernetes 自定义资源的出处信息。


github.com/cloud-ark/kubeprovenance


KubePug


这是一个 kubectl 插件，可以从特定的 Kubernetes 版本下载 swagger.json，解析此 Json 查找弃用通知，并检查集群是否已弃用 API 版本。


github.com/rikatz/kubepug


KubeRig


这是针对 Kubernetes/OpenShift 的开源部署自动化工具，它通过用 Kotlin 编写的 DSL 定义 Kubernetes 资源（而不是常规的 YAML）。


github.com/kuberig-io/kuberig


Kubermatic


这是适用于任何基础架构的 Kubernetes 集群管理自动化平台。


github.com/Kubermatic/Kubermatic


kubernaughty


这是一个关于调试和识别 Kubernetes/容器工作负载故障、性能和可靠性注意事项等的文档。


github.com/jnoller/kubernaughty


kubernetes-goat


这是一种被故意设计为易受攻击的集群环境，用来学习和实践 Kubernetes 的安全性。


github.com/madhuakula/kubernetes-goat


kubernix


该项目旨在为本地测试、实验和开发提供单一依赖的 Kubernetes 集群。


github.com/saschagrunert/kubernix


kubespy


这是一个实时观察 Kubernetes 资源的工具。


github.com/pulumi/kubespy


kubetail


这是一个小型的 Bash 脚本，它允许将来自多个窗格的日志聚合到一个流中。


github.com/johanhaleby/kubetail


kubetap


这是一个 kubectl 插件，可以为 Kubernetes Services 部署拦截代理。


github.com/soluble-ai/kubetap


kubethanos


该项目会随机杀死一半的 Pod，在环境中控制混乱，以此查看系统在故障情况下的情况。


github.com/berkay-dincer/kubethanos


Kubetools


Kubernetes 工具精选清单，涵盖最流行的工具和技术，并针对这些工具提出最佳实践。


dockerlabs.collabnix.com/kubernetes/kubetools


KubeVault


这是一个用于在 K8s 上运行 HashiCorp Vault 的工具集。


github.com/kubevault


kubevious


这个工具可为 Kubernetes 提供可用的高度图形化界面，它把与该应用程序相关的所有配置集中在一处，可以帮助开发者节省时间。


github.com/kubevious/kubevious


kubie


它是 kubectx、kubens 的替代品，能在每个 shell 彼此独立的情况下进行上下文切换、命名空间切换和快速修改。


github.com/sbstp/kubie


KubiScan


它可以在 Kubernetes 的基于角色的访问控制（RBAC）授权模型中扫描 Kubernetes 集群以获取相应权限。


github.com/cyberark/KubiScan


kured


这是一个 Kubernetes 守护程序集，当基础 OS 的软件包管理系统指示需要执行某些操作时，该节点将执行安全的自动节点重新启动。


github.com/weaveworks/kured


kuttle


这个工具可以帮助开发者轻松访问 Kubernetes 网络环境，不需要 SSH 访问。


github.com/kayrus/kuttle


kvdi


它是虚拟桌面基础架构（Virtual Desktop Infrastructure）的 Kubernetes operator。


github.com/tinyzimmer/kvdi


kyaml2go


这是来自 Kubernetes 资源规范 yaml 的 Go 客户端代码生成器。


github.com/PrasadG193/kyaml2go


M
magicpak


它可以构建最小的 Docker 镜像，而无需例如 static linking 的准备工作。


github.com/coord-e/magicpak


mikt


这是一种 Managed Kubernetes 检查工具，可验证 Managed Kubernetes 集群和内部工作负载、资源的安全性相关配置。


github.com/darkbitio/mkit


N
network-node-manager


这是一个 kubernetes 控制器，它控制节点的网络配置以解决 kubernetes 网络问题。


github.com/kakao/network-node-manager


nodalingresser


这个工具能使 GKE worker nodes 更易于在公共互联网上访问，可避免因使用 ILB 每月需花费 20 美元。


github.com/jacobstr/nodalingresser


node-feature-discovery


这个工具可以检测 Kubernetes 集群中每个节点上可用的功能，并使用节点标签发布这些功能。


github.com/kubernetes-sigs/node-feature-discovery


node-problem-detector


这个工具旨在收集来自各节点的问题，并使它们对上层可见。


github.com/kubernetes/node-problem-detector


NodeWrecker


NodeWrecker 允许你对集群 CPU、内存或磁盘负载进行压力测试，方便设计混沌工程实验。


github.com/jaeg/NodeWrecker


O
oneinfra


它用于跨不同公有云、私有云和裸金属服务器管理和运行多个 Kubernetes 集群。


github.com/oneinfra/oneinfra


oomhero


这是一种辅助工具，可帮助开发者跟踪容器的内存使用情况。


github.com/ricardomaraschini/oomhero


operator-lifecycle-manager


这是用于通过 Operators 扩展 Kubernetes 管理框架的工具包。


github.com/operator-framework/operator-lifecycle-manager


P
pangolin


它是用于 Kubernetes 的水平 Pod 自动伸缩器，它使用各种可配置的控制策略，根据 Prometheus 指标扩展 Deployment。


github.com/dpeckett/pangolin


permission-manager


该工具提供了一种简单直观的方式来管理 Kubernetes 集群中的用户。


github.com/sighupio/permission-manager


pluto


它能帮助用户在其代码存储库和 Helm 版本中找到已弃用的 Kubernetes apiVersion。


github.com/FairwindsOps/pluto


podtnl


这是一个 CLI 工具，可在不公开 Kubernetes 服务的情况下使 Pod 在线可用。


github.com/narendranathreddythota/podtnl


Polaris


这是一款通过分析部署配置，发现集群中存在的问题的健康检查组件，也提供问题的解决方案，确保集群处于健康状态。


github.com/FairwindsOps/polaris


pomerium


这是一种身份识别代理，提供了跨云和本地部署一致的身份验证、授权、工具和审核。


github.com/pomerium/pomerium


popeye


这个工具可扫描活动的 Kubernetes 集群并报告已部署资源和配置的潜在问题。


github.com/derailed/popeye


porter


这是为 Kubernetes 裸机集群设计的开源负载均衡器。


github.com/kubesphere/porter


postgres-operator


这是 PostgreSQL 运算符，可在 Kubernetes上 创建、配置、管理 PostgreSQL 集群。


github.com/CrunchyData/postgres-operator


powerfulseal


这是用于 Kubernetes 集群的强大测试工具，它会给 Kubernetes 集群增加了混乱以帮助我们尽早发现系统中的问题。


github.com/powerfulseal/powerfulseal


predictive-horizontal-pod-autoscaler


这是一个自定义 Pod 自动缩放器。


github.com/jthomperoo/predictive-horizontal-pod-autoscaler


preflight


这是是使用 Open Policy Agent（OPA）自动执行 Kubernetes 集群配置检查的工具。


github.com/jetstack/preflight


push-deploy


这是一个 Python 应用，可安全、简单地实现外部工具（GitHub Actions 等）与 Kubernetes 之间的通信，无需暴露集群凭证。


github.com/mdgreenwald/push-deploy


R
rafter


这个项目是用于存储和管理不同类型文件的解决方案，它使用 MinIO 作为对象存储。


github.com/kyma-project/rafter


rback


这是一个简单的 Kubernetes RBAC 的可视化工具。它可以查询 Kubernetes 集群中所有与 RBAC 相关的信息，并以点格式生成相关图表。


github.com/team-soteria/rback


registry-creds


这是一个 Kubernetes operator，可用于将单个 ImagePullSecret 分发到集群中的所有命名空间空间，以通过身份验证提取镜像。


github.com/alexellis/registry-creds


Reloader


Reloader 是 Kubernetes 控制器，可监控 ConfigMap 和 Secrets 中的更改并触发 Pods 及其关联的 Deployment、StatefulSet、DaemonSet 和 DeploymentConfig 的滚动升级。


github.com/stakater/Reloader


S
secretize


这是一个 Kustomize 插件，可用于生成 kubernetes secret。


github.com/bbl/secretize


secrets-store-csi-driver


它可以让 Kubernetes 将在外部存储中的密钥、证书等作为卷放到 Pod 上。


github.com/kubernetes-sigs/secrets-store-csi-driver


shell-operator


这是在 Kubernetes 集群中运行事件驱动脚本的工具。


github.com/flant/shell-operator


sinker


它可以将容器镜像从一个注册表同步到另一个。


github.com/plexsystems/sinker


stale-feature-branch-operator


它用于删除 Kubernetes 集群中的陈旧功能分支。


github.com/dmytrostriletskyi/stale-feature-branch-operator


stash


这是针对 Kubernetes 工作负载的云原生数据备份和恢复解决方案。


github.com/stashed/stash


statusbay


这是一个可视化 k8s 部署过程的项目，它从 k8s 收集所有相关事件并展示部署过程，以帮助 k8s 故障排除。


github.com/similarweb/statusbay


stolon


这是一个云原生 PostgreSQL 管理器，使用 Kubernetes API Server 作为高可用数据存储来选举领导者。


github.com/sorintlab/stolon


sugarkube


一个可以创建临时 Kubernetes 集群的工具。仅需几个命令，你就可以启动和配置 Kubernetes 集群，将所有应用程序安装到其中，并创建所需的基础架构。


github.com/sugarkube/sugarkube


suspicious-pods


列出 Kubernetes 集群中可能无法正常工作的 Pod 列表，附带原因。


github.com/edrevo/suspicious-pods


sysbox


这是一个开源的容器 runtime。


github.com/nestybox/sysbox


T
terraform-kubestack


这是基于 Terraform 和 Kustomize 构建的开源 Gitops 框架。


github.com/kbst/terraform-kubestack


ThreatMapper


它可以用于识别正在运行的容器、镜像、主机和存储库中的漏洞。


github.com/deepfence/ThreatMapper


tobs


它能将完整的可观察性堆栈简单地安装到 Kubernetes 集群中。


github.com/timescale/tobs


trivy


这是一种适用于 CI 的简单而全面的容器漏洞扫描程序。


github.com/aquasecurity/trivy


tubekit


这是一个围绕 kubectl 的简单而强大的封装器，可降低使用上下文、命名空间和智能匹配资源的复杂性。


github.com/reconquest/tubekit


V
velero-backup-notification


这是一个用 Ruby 编写的简单 Kubernetes 控制器。


github.com/vitobotta/velero-backup-notification


version-checker


它用于观察集群中运行镜像的当前版本以及上游可用的最新版本。


github.com/jetstack/version-checker


vim-helm


Helm templates 的 vim 语法（yaml + gotmpl + sprig + custom）。


github.com/towolf/vim-helm


W
weathervane


这是一个应用程序级性能基准工具，可用于研究内部部署和基于云的 Kubernetes 集群的性能特征。


github.com/vmware/weathervane


webkubectl


这个工具可以帮助开发者管理 Kubernetes 凭证并在浏览器中运行 kubectl 命令，支持团队协作。


github.com/KubeOperator/webkubectl


wild-west-kubernetes


这是一个用 Spring Boot 和 Phaser 游戏引擎编写的有趣应用程序。


github.com/gshipley/wild-west-kubernetes


X
xlskubectl


它可以用 Excel 表格控制 kubernetes 集群。


github.com/learnk8s/xlskubectl


Y
yh


这是一个 YAML 突出显示器，可以将其与 kubectl 结合使用。


github.com/andreazorzetto/yh


]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>IDEA插件 - Java 热部署HotSeconds，可实现一键化秒级热更新</title>
    <url>/posts/77145.html</url>
    <content><![CDATA[前言
我们在开发调试的过程中，经常在打包和重启服务器中消耗大量的时间，这将浪费我们大量的青春，这里介绍一款本人开发的 Java 远程热部署插件 HotSeconds ，包括 HotSecondsServer 和 HotSecondsClient ，相对传统部署来说，效率可以提升百倍。
功能介绍
1.热部署代码
包括修改代码，新增字段，新增方法，新增类，打破了原生 JDK 中 Instrument 机制只能修改方法体的不足。同时还支持一些常用框架的热更新，比如 Spring 新增一个 Autowired 字段或者 SpringMVC 新增一个 Controller 方法，也是支持热更新的。
2.热部署资源文件
在资源文件上右键也可以选择 Hot swap this file to remote ，比如 MyBatis 的 xml 文件，就能直接热更新生效，那么资源文件是怎么实现热部署的呢？ 这里是根据 Path mappings 中的路径映射，将本地的资源文件热部署到远程对应目录，但是资源文件非常复杂，比如 xml ,html, css, js ，properties 等等文件，框架也非常的多，又是怎么实现热部署的呢？ 路径映射只是将文件上传到服务器端，真正生效的是上传完之后刷新资源文件的缓存的逻辑，这就涉及到插件扩展，本插件内核集成了 MyBatis 和 MyBatis Plus 的 xml 的热更新，更多的资源文件热更新，详见插件扩展。
3.批量热更新修改的文件
修改了多个文件的情况下，直接打开热部署面板，可将修改过的文件热部署到服务器，支持按文件修改时间戳热部署，也可以将版本控制下(Git/SVN 等)未提交的文件热部署
4.执行远程函数
无需调用远程 Http 或者 RPC 接口，就能直接触发需要的函数，这对于调试来说可是非常方便的，当然也包括在沙箱环境修复脏数据。
直接在函数上右键选择远程执行函数，即可触发具体的函数逻辑，这里分为四种情况，静态，非静态，有参数，无参数。
无参数可以直接触发，如果是非静态字段，会弹出当前类的所有对象的选择框，选择后触发。
有参数的情况，会弹出对象选择框和参数输入框，输入选择后触发逻辑。
目前参数只支持 byte,short,boolean,char,int,double,float,long,BigDecimal 。
复杂参数的函数，可以写一个静态无参的函数，触发需要的函数，然后远程热部署整个新写的静态无参的函数的类即可。
5.远程查看字段值
包括静态字段和非静态字段，直接在字段上右键，就能查看该字段的值。 非静态字段是先弹出显示当前类的所有对象实例的框，选择具体的对象后即可获取该对象的字段值。
6.jar 包热更新
在打开的 jar 上面右键，可以看到两个选项，Hot deploy the Jar to remote 和 Hot swap this file to remote 。 前者是将整个 jar 的所有 class 热部署的服务器，后者只热更新选中的 class 。
7.远程编译并热部署
在 java 文件上右键选中 Hot swap this file to remote ，会在本地编译然后热更新到远程，但是有的时候本地编译并不方便，比如本地和远程服务器的 JDK 版本可能存在巨大的差异，这个时候就需要远程编译了。
在 java 文件上右键，选择 Remote compilation and hot swap 可以在远端编译并热更新。
安装教程
详见https://github.com/Liubsyy/HotSecondsIDEA
]]></content>
      <categories>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title>Podman 与 Docker</title>
    <url>/posts/771236.html</url>
    <content><![CDATA[Podman 与 Docker：比较两种容器化工具

容器技术已成为软件开发与部署的核心工具，其中Docker领跑行业，而Podman作为后来者提供了新的选择。两者都兼容开放容器计划（OCI）标准，并拥有完善的容器管理特性。选择它们之一取决于个别用例，每种工具都有其场景更支持的专长。我们提供的对比指南将详细介绍它们各自的优点和应用场景，帮助用户依据自身的需求作出合适的选择。

1. 什么是容器？

容器为开发者提供一种打包应用程序及其依赖项的方法，使它们能在不同环境中无缝运行，提供了隔离但资源高效的解决方案。这种技术通过容器映像，即一套可以复制的应用程序和环境说明，实现可移植性。现代容器化工具如Docker和Podman均符合OCI标准，支持交互性，并能管理和传播这些容器映像，确保它们能在不同系统中快速运行。

2. 什么是 Docker？

Docker 是一个通过容器创建、部署和管理应用程序的平台。借助 Docker，您可以使用 Dockerfile（用于创建容器的脚本）或现有容器映像创建符合 OCI 标准的容器。


Docker 已经成为一种非常流行的容器化工具，至少部分原因是它相对简单。其简单明了的命令和丰富的可用文档使 Docker 变得非常容易上手。

3. 什么是 Podman？

Podman 和 Docker 一样，是一个用于部署和管理容器化应用程序的开源引擎。Podman 从现有映像或 Containerfile 和 Dockerfile 构建符合 OCI 标准的容器。


Podman 引擎最初由 Red Hat 开发，旨在提供 Docker 的无守护进程替代方案。通过采用无守护进程架构，Podman 试图解决围绕 Docker 基于守护进程的安全问题。


此外，Podman 的无守护进程架构赋予了它真正的无根模式。Docker 命令可以由非 root 用户运行，但执行这些命令的守护程序继续在 root 上运行。相反，Podman 直接执行命令，避免了对 root 权限的需求。

4. Docker 与 Podman

Podman 和 Docker 都是容器化工具。使用任何一种方式，您都可以完全启动、部署和管理容器。


但是，每种工具都有其优点和缺点。接下来的几节将逐一探讨，并提供了一个列表来比较和对比这两个容器化引擎。

5. Docker 的优点和缺点
Docker 优点：


简单易近人。Docker 的命令设计得相对简单易用。除此之外，Docker 还维护着最常用的容器映像注册表之一。
Docker Hub 拥有大量维护良好的容器映像，其中许多映像是官方编写和更新的。例如，这使得拉取 LAMP 堆栈的容器映像并开始快速使用 Docker 变得相对容易。
流行。Docker 的广泛使用意味着您更有可能在任何与容器一起使用的地方遇到它。这也意味着您拥有大量且易于访问的用户文档和故障排除集合。


Docker 缺点：


基于守护程序的体系结构。Docker 运行在长时间运行的守护进程上，这可能会给某些人带来安全问题。此外，该守护进程以 root 权限运行。因此，即使是执行 Docker 命令的有限用户也会通过具有 root 权限的进程来完成这些命令，这是另一个安全问题。


6. Podman 的优点和缺点
Podman 优点：


无守护进程架构。Podman 直接与容器和容器映像交互，无需长时间运行的守护进程。这样做可以减少安全风险。




无根进程。由于其无守护进程架构，Podman 可以执行真正的无根操作。用户不必被授予 root 权限即可运行 Podman 命令，并且 Podman 不必依赖具有 root 权限的进程。




访问映像注册表。Podman 可以从众多注册表（包括 Docker Hub）中查找和拉取容器映像。这意味着，只需稍加配置，Podman 就可以访问与 Docker 相同的镜像仓库。


Podman 缺点：


有限的构建功能。Podman 主要关注运行和管理容器。它可以构建容器并将其呈现为图像，通常对许多用例有效。但是，它这样做的功能代表了 Buildah 源代码的有限部分。
相反，Podman 支持将 Buildah 用作功能更丰富的容器构建和对流程进行微调控制的免费工具。


7. 何时使用 Docker

Docker 最适合需要更平易近人的容器化选项。Docker 的设计使其上手速度相对较快，其功能集包括您在使用容器时可能需要的一切。


Docker 涵盖了整个容器生命周期，从容器组合到部署和维护。它通过一组简单的命令来实现这一点。


Docker 已经在许多公司建立了使用，并且拥有大量使用经验的人。在容器化工具方面，与大多数其他工具相比，您更有可能找到熟悉 Docker 的人。

8. 何时使用 Podman

Podman 提供更高的安全性选项。它的无守护进程架构允许你运行无根容器。这与 Podman 用于管理容器的直接（而不是长时间运行）流程相结合，进一步保护了它们。


Podman 是一种轻量级的专业解决方案。它侧重于运行、部署和管理容器，并为您提供对这些流程的精细控制。


同时，提供了用于构建容器和映像的选项，尽管这些选项有限。Podman 始终专注于其专业化，并更喜欢将 Buildah 作为构建容器和容器映像的免费工具。


这种专业化和轻量级占用空间在以下情况下非常有用：你希望对运行和管理容器进行更多控制，但不需要更高级的生成功能（或能够依赖其他工具）。


事实上，考虑到 Docker 和 Podman 都符合 OCI 标准，您可以有效地并行使用 Docker。例如，您可以将 Docker 用于开发环境，在该环境中创建应用程序映像，但安全性问题不大。然后，使用 Podman 在生产环境中运行和维护这些映像。

]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>Typora Markdown编辑器激活方法</title>
    <url>/posts/233291.html</url>
    <content><![CDATA[1.官网下载安装
https://www.typoraio.cn/

2.不运行软件的情况下，进入安装目录打开 LicenseIndex.180dd4c7.5c394f9a.chunk.js 文件
安装盘符(默认C盘):\Typora\resources\page-dist\static\js\LicenseIndex.180dd4c7.5c394f9a.chunk.js

3.搜索关键代码e.hasActivated=“true”
将搜索到的位置的【e.hasActivated=&quot;true&quot;==】 后面添加 【&quot;true&quot;,】
即：e.hasActivated=&quot;true&quot;==&quot;true&quot;,
或者是
【e.hasActivated=&quot;true&quot;==e.hasActivated】改为e.hasActivated=&quot;true&quot;==&quot;true&quot;

]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>VPN|wireguard红龍搭建教程</title>
    <url>/posts/2950.html</url>
    <content><![CDATA[正文:
在这个数字化和互联网高度发达的时代，数据安全和隐私无疑成了我们的首要关注点。红龍，一个领先的远程连接速度解决方案的工具，不仅以其强大的性能为公众所熟知，还陆续证明了它在数个重要应用场景中的价值。

附上红龍客户端下载网址


红龍的框架图解
应用红龍不仅局限于游戏、电商或海外直播，它的确拓宽了我们对传统VPN技术的认知。以下是红龍默默助力的几个其他用途方面：

安全的远程访问：连接到你的企业网络或个人网络从未如此安心，RedDragon确保通过公开互联网的每次访问都受到保护。
公共Wi-Fi的保镖：在不受保护的公共Wi-Fi网络上，RedDragon就像你的私人隐形盾牌，保护数据传输免遭窥探。
跨网络界的桥梁：为公司的分支机构、云服务以及跨地域团队节省时间和金钱，通过红龍建立一道安全、可靠的网络通路。
网上行的隐士：探索互联网的同时，红龍确保你的行踪不为他人所知，提供你所期望的匿名性。
秘密通讯的守护者：无论何时何地上网，防止监视和数据追踪就是红龍承诺的隐私保护。
连接云端的隐秘通道：在许多云服务设置中亦能轻松应用，确保高度敏感的工作负载安全地处于加密隧道之中。
虚拟局域网络的枢纽之选：迅捷地将遥远的设备安全引互入局域网，使它们仿佛就在您的书桌旁边。

为便利您搭建自己的红龍，以下是快速部署该工具的步骤：
步骤1：更新系统
执行以下命令以更新系统和安装最新的安全补丁。
sudo apt update
sudo apt upgrade -y

步骤2：安装Docker
使用以下命令快速安装Docker，帮助我们容器化红龍。
curl -sSL https://get.docker.com | sh
sudo usermod -aG docker $(whoami)
exit

步骤3：运行红龍容器
我们借助于Docker容器化的优势来部署红龍服务。执行如下命令：
docker run -d \
  --name=WG-SCX \
  -e WG_HOST=您的域名或IP地址 \
  -e PASSWORD=随机字符密码 \
  -e WG_DEFAULT_DNS=8.8.8.8,8.8.4.4 \
  -v ~/.wg-easy:/etc/wireguard \
  -p 51820:51820/udp \
  -p 51821:51821/tcp \
  --cap-add=NET_ADMIN \
  --cap-add=SYS_MODULE \
  --sysctl=&quot;net.ipv4.conf.all.src_valid_mark=1&quot; \
  --sysctl=&quot;net.ipv4.ip_forward=1&quot; \
  --restart unless-stopped \
  weejewel/wg-easy


红龍配置示范
以上步骤将帮助您启动并运行红龍协议，立即享受一流的安全上网体验。
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>VPN</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo配置详解</title>
    <url>/posts/21129.html</url>
    <content><![CDATA[1. Hexo 文章的元数据配置完全指南
Hexo 强大的功能部分归功于它的元数据配置，即 Front-matter，这些配置项位于 Markdown 文件顶部，并影响着文章的显示和行为。本文章深入解析了 Hexo 博客文章中各项元数据配置，帮助你更精确地控制文章的展示。
---
title: Your Title Here
date: YYYY-MM-DD HH:MM:SS
author: Your Name
img: http://example.com/feature-image.jpg
top: true
hide: false
cover: false
coverImg: http://example.com/cover-image.jpg
password: your-sha256-encypted-password
toc: true
mathjax: false
summary: Your custom article summary.
categories: Category
tags: 
  - Tag1
  - Tag2
keywords: Keyword1, Keyword2, Keyword3
reprintPolicy: cc_by
---

# Your Title Here

Your article content starts here.


请记得将上述模板中的占位（例如 Your Title Here 或 YYYY-MM-DD HH:MM:SS）替换成相应的信息。
解释一下每个配置的作用：



配置选项
默认值
描述




title
Markdown 文件标题
文章标题，应明确填写以便识别。


date
文件创建时间
发布时间对于排序很重要，建议设为唯一。


author
_config.yml的author值
文章的作者名。


img
random featureImages值
文章特色图像，推荐使用可依赖的CDN服务。


top
true
是否将文章置顶在博客首页。


hide
false
设为true则文章不显示在首页。


cover
false
自 v1.0.2 起，加入是否作为首页轮播封面文章。


coverImg
无
首页轮播封面图片路径，如未指定使用img作为默认。


password
无
文章密码，使用SHA256加密，激活主题配置中的verifyPassword功能。


toc
true
是否为文章生成目录。


mathjax
false
是否为文章启用MathJax解析数学公式。


summary
无
自定义文章摘要，如果为空自动截取内容。


categories
无
文章分类，建议单分类以维护结构清晰。


tags
无
文章的标签，可以有多个。


keywords
文章标题
关键词有助于SEO。


reprintPolicy
cc_by
文章的转载规则，根据需求选择。



注意：

如果你放置了 password，那么只有获知密码的读者才能访问这篇文章。
cover 和 coverImg 选项，在主题版本 v1.0.2 及以后版本中才开始支持。
'summary’可以让您控制显示在文章列表上的简介内容。
数学公式（mathjax）和TOC（toc）的特有选项需要在主题的配置文件中开启。
正确设置SEO相关字段（keywords, summary）有助于提高搜索引擎排名。

后续更新
]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>一键搭建ChatGPT Next Web跨平台私人 ChatGPT</title>
    <url>/posts/35029.html</url>
    <content><![CDATA[1.开始使用

准备好你的 OpenAI API Key;
点击右侧按钮开始部署：部署，直接使用 Github 账号登录即可，记得在环境变量页填入 API Key 和页面访问密码 CODE；
部署完毕后，即可开始使用；
（可选）绑定自定义域名：Vercel 分配的域名 DNS 在某些区域被污染了，绑定自定义域名即可直连。

2.保持更新

如果你按照上述步骤一键部署了自己的项目，可能会发现总是提示“存在更新”的问题，这是由于 Vercel 会默认为你创建一个新项目而不是 fork 本项目，这会导致无法正确地检测更新。 推荐你按照下列步骤重新部署：



删除掉原先的仓库；
使用页面右上角的 fork 按钮，fork 本项目；
在 Vercel 重新选择并部署，请查看详细教程。


3.打开自动更新

如果你遇到了 Upstream Sync 执行错误，请手动 Sync Fork 一次！


当你 fork 项目之后，由于 Github 的限制，需要手动去你 fork 后的项目的 Actions 页面启用 Workflows，并启用 Upstream Sync Action，启用之后即可开启每小时定时自动更新：



4.配置页面访问密码

配置密码后，用户需要在设置页手动填写访问码才可以正常聊天，否则会通过消息提示未授权状态。


警告：请务必将密码的位数设置得足够长，最好 7 位以上，否则会被爆破。


本项目提供有限的权限控制功能，请在 Vercel 项目控制面板的环境变量页增加名为 CODE 的环境变量，值为用英文逗号分隔的自定义密码：
增加或修改该环境变量后，请重新部署项目使改动生效。

5.环境变量

本项目大多数配置项都通过环境变量来设置，教程：如何修改 Vercel 环境变量。



OPENAI_API_KEY （必填项）
OpanAI 密钥，你在 openai 账户页面申请的 api key，使用英文逗号隔开多个 key，这样可以随机轮询这些 key。




CODE （可选）
访问密码，可选，可以使用逗号隔开多个密码。



警告：如果不填写此项，则任何人都可以直接使用你部署后的网站，可能会导致你的 token 被急速消耗完毕，建议填写此选项。



BASE_URL （可选）
Default: https://api.openai.com
Examples: http://your-openai-proxy.com
OpenAI 接口代理 URL，如果你手动配置了 openai 接口代理，请填写此选项。
如果遇到 ssl 证书问题，请将 BASE_URL 的协议设置为 http。




OPENAI_ORG_ID （可选）
指定 OpenAI 中的组织 ID。




AZURE_URL （可选）
形如：https://{azure-resource-url}/openai/deployments/{deploy-name}



Azure 部署地址。



AZURE_API_KEY （可选）
Azure 密钥。




AZURE_API_VERSION （可选）
Azure Api 版本，你可以在这里找到：Azure 文档。




GOOGLE_API_KEY (optional)
Google Gemini Pro 密钥.




GOOGLE_URL (optional)
Google Gemini Pro Api Url.




HIDE_USER_API_KEY （可选）
如果你不想让用户自行填入 API Key，将此环境变量设置为 1 即可。




DISABLE_GPT4 （可选）
如果你不想让用户使用 GPT-4，将此环境变量设置为 1 即可。




ENABLE_BALANCE_QUERY （可选）
如果你想启用余额查询功能，将此环境变量设置为 1 即可。




DISABLE_FAST_LINK （可选）
如果你想禁用从链接解析预制设置，将此环境变量设置为 1 即可。




CUSTOM_MODELS （可选）
示例：+qwen-7b-chat,+glm-6b,-gpt-3.5-turbo,gpt-4-1106-preview=gpt-4-turbo 表示增加 qwen-7b-chat 和 glm-6b 到模型列表，而从列表中删除 gpt-3.5-turbo，并将 gpt-4-1106-preview 模型名字展示为 gpt-4-turbo。 如果你想先禁用所有模型，再启用指定模型，可以使用 -all,+gpt-3.5-turbo，则表示仅启用 gpt-3.5-turbo



用来控制模型列表，使用 + 增加一个模型，使用 - 来隐藏一个模型，使用 模型名=展示名 来自定义模型的展示名，用英文逗号隔开。

参考项目
ChatGPT-Next-Web
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>又一款AI产品Photoshop插件StartAI</title>
    <url>/posts/2132.html</url>
    <content><![CDATA[1. 介绍

作为设计师，您可能一直在寻找那些能让艺术创作变得更简单更高效的工具，而 StartAI PS 插件 正是为此而生。这是一个基于 Adobe Photoshop 的强大 AI 插件，不仅助您深度挖掘艺术潜能，更是速提工作效率的得力帮手。无论是绘画、摄影、设计还是其他艺术流派，该插件都能如艺术之灵魂般激发您的创意无限。


想了解更多？访问官网：StartAI

核心功能

文生图： 构想变现实，瞬间生成
生成相似图： 边界拓展，相似而不同
局部重绘： 瑕疵消除，细节凸显
线稿上色： 色彩饱和，无畏挑战
无损放大： 高倍处理，清晰如初
扩图： 界限扩张，可能性延展
艺术风格融合： 文艺碰撞，风格迸发


兼容本地与远程引擎，支持Stable Diffusion、Midjourney 等多个绘图引擎。

2. 先决条件与安装指南
2.1 先决条件

确保您已安装 Adobe Photoshop 并且版本为 Photoshop CC 2015（18.0）或以上。


若不知道版本，可点击 Photoshop 顶部菜单栏的「帮助」，然后选择「关于 Photoshop」检查版本号。

2.2 下载与安装
注册与下载

访问 StartAI 官网，注册账号并登录后一键下载安装包。

安装插件


在安装前，确保 Photoshop 已关闭；


双击打开下载的 StartAIInstall.exe 文件，遵循步骤安装；


插件安装无需额外配置，完成后打开Photoshop 即可使用。


2.3 插件启动


您可以通过桌面直接启动 StartAI，或在打开 Photoshop 时它将自动启用。之后可以在 Photoshop 界面内移动或停靠 StartAI PS 插件。


通过 Photoshop 顶部菜单栏的「帮助 &gt; 关于增效工具」，也可以找到并开启 StartAI PS 插件。


3. 用户登录
注册账号包含以下步骤：


在 StartAI 官网点击「注册」，进入账号注册页面；


填写您的邮箱和邮箱验证码；


设置登陆密码；


输入邀请码完成注册（注：当前处于内测阶段，需要内测邀请码才可注册账号）。


获取邀请码的途径：


向获得内测资格者请求；


加入 StartAI 的 QQ 频道【StartAI】(https://pd.qq.com/s/9w8nf5hmy)，也可联系管理员获取邀请码。


登录账号：

打开 StartAI PS 插件，用注册邮箱和密码登录后直达主界面。


此文章仅用于指导，详情可访问 StartAI 官网。
]]></content>
      <categories>
        <category>PS</category>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>PS</tag>
      </tags>
  </entry>
  <entry>
    <title>壹伴排版Plus脚本VIP破解</title>
    <url>/posts/29572.html</url>
    <content><![CDATA[概述

壹伴是一款浏览器插件，可以通过它来给公众号进行快速排版！
基本上做公众号的小伙伴都知道这款插件！
官网：https://yiban.io/
使用壹伴插件前请确保你已经：
1、安装了壹伴插件
2、安装了油猴插件


有条件的可以支持一下 点这里可以免费获得一个月官网

教程开始
1、安装油猴脚本

https://greasyfork.org/zh-CN/scripts/439551-壹伴排版-plus

2、登录

公众号的后台，并点击草稿箱-创建新的图文

3、编辑

点击菜单栏「油猴插件」，找到「壹伴排版Plus」插件，点击编辑


4、修改

按下快捷键「Ctrl + F」输入“.parents”

将.parents('.style-waterfall-inner') 把这行代码修改为 .parents('.material-item-li-inner')


5、保存

点击上方的「设置」，取消检查更新并保存


6、开启

回到公众号界面，点击浏览器右上角「壹伴」插件，按提示登录插件
点击开启「壹伴」插件的菜单，你会发现所有带有vip的排版样式，你都可以直接使用了！




此插件已不能用，待作者更新https://greasyfork.org/zh-CN/scripts/439551-壹伴排版-plus
以上参考文章 壹伴排版Plus脚本VIP破解

]]></content>
      <categories>
        <category>公众号</category>
      </categories>
      <tags>
        <tag>公众号</tag>
        <tag>破解</tag>
      </tags>
  </entry>
  <entry>
    <title>如何快速部署一个Gemini Pro Chat机器人：3分钟使用Vercel教程</title>
    <url>/posts/31594.html</url>
    <content><![CDATA[
在这个数字化的世界里，即便你是编程的初学者，也能迅速踏入机器人开发领域。借助Vercel这一云平台，你可以轻松快捷地部署属于自己的Gemini Pro Chat机器人Web界面。本教程将带你从零基础开始，一步步完成机器人的在线部署，同时简要介绍必要的技术概念，助你快速上手。

第一步：获取您的Gemini API密钥

首要任务是访问Google创作者工具以获取Gemini API密钥。详细步骤可参考以下链接：

点击以获取Gemini API Key

获取API密钥后，请妥善保管，这将在后续的部署中使用。以下是获取API密钥的参考截图：



确保你选择了“创建一个新的API”选项，并按照提示继续操作。



按照流程操作完成后，你的API密钥就已经准备就绪。


第二步：Vercel一键部署

现在，我们将利用Vercel进行机器人的一键部署。首先，前往Gemini Pro Chat的官方GitHub项目页面：

访问Gemini Pro Chat GitHub仓库

你将在页面上找到方便的Vercel一键部署按钮。



登录您的Vercel账号并创建自己的Git仓库：



根据需要确认您的项目配置信息：



点击部署（Deploy）按钮后，Vercel将自动开始部署您的项目。


一旦部署完成，您就可以通过Vercel提供的专属链接访问您的机器人了。


请注意，目前该机器人尚不支持图像对话功能。



想要了解更多部署选项，比如使用Railway、Zeabur、Docker或者在本地运行机器人，您可以在GitHub项目的README.md文件中找到完整的部署指南。

]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>ChatGpt</tag>
        <tag>建站</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建Hexo博客遇到的问题</title>
    <url>/posts/23329.html</url>
    <content><![CDATA[1. hexo 如何删除已经不存在的“分类”

因缓存的问题，重新清理执行脚本即可,如下是 清理-生成-发布 命令

    hexo clean &amp;&amp; hexo g &amp;&amp; hexo de

2. 解决Hexo部署报错：Error: Spawn failed
在使用Hexo部署你的博客到GitHub时，你可能会遇到一个错误提示：Error: Spawn failed。
这个错误往往是因为本地Git的提交记录与GitHub上的记录不同步导致的。
2.1 问题诊断
部署错误可能发生在执行 hexo g -d命令时，由于.git目录中文件的不统一而引发。发生这种情况可能是因为之前的部署有些失败或误操作导致本地和远程仓库历史记录不一致。
2.2快速修复指南
这里介绍一个快速修复的步骤：


检查提交记录差异
打开命令行，先检查你在.deploy_git目录中的提交记录。
cd .deploy_git
cat .git/logs/HEAD

记录下你看到的最后一个提交的commit代码（Hash），如280a7fdd46fcfd7d34e652aec15523dcd247fac8。


对比GitHub提交记录
访问GitHub Pages服务所关联分支的提交历史，回顾最近一次提交的标识。该界面URL的格式通常是https://github.com/username/repository/commits/branch。例如: https://github.com/lxl80/blog/commits/gh-pages。


确认并同步记录
如果你发现本地的记录和远程的记录出现不一致，你需要将本地记录同步到远程记录的状态。
执行下列命令，将本地提交记录硬重置为GitHub上最新的提交标识：
git reset --hard f085038efdf79546c09641d37b2a2429c1ae8e60

替换 f085038efdf79546c09641d37b2a2429c1ae8e60 至远端仓库的实际最后一次提交标识。


重新部署
完成上述步骤后，你可以再尝试重新部署你的Hexo博客。
hexo g -d



3. 如何在您的网站上悬挂灯笼庆祝新年
为了庆祝新年并给您的网站添加一些节日气氛，您可以利用一个名为LanternJS的JavaScript库。这个库能够让您快速地在网站上加上漂亮的节日灯笼特效。
3.1 集成灯笼特效
首先，您需要了解LanternJS这个库的配置，并且获取所需文件的链接。LanternJS的项目页面在GitHub上可以找到，地址是：

LanternJS的README

参考该文档，您就可以准备好将灯笼加入到您的网站之中。下面是整合这个库到您Hexo主题所需关键步骤。
3.2 添加脚本到Hexo主题
您想要将代码添加到您的Hexo主题的 header.ejs 文件。该文件的路径一般是 hexo-theme-matery/layout/_partial/header.ejs。
下面是灯笼功能的HTML和JavaScript代码片段。在文件合适的位置插入以下代码：
&lt;script src=&quot;https://cdn.jsdelivr.net/npm/hexo-lanternjs@1.0.0/lantern.min.js&quot;&gt;&lt;/script&gt;
&lt;div id=&quot;lantern-wrapper&quot; class=&quot;lantern-wrapper&quot; no-select&gt;&lt;/div&gt;
&lt;script&gt;
	let lantern = new Lantern('lantern-wrapper', &#123;
		date: &#123;								// 日期配置
			from: '12-20',					// 灯笼开始出现的日期
			to: '3-31'						// 灯笼消失的日期
		&#125;,
		position: &#123;						    // 灯笼的位置配置
			zIndex: 9999,					// 灯笼的层级
			lanternRL: [10, 150, 150, 10],	// 灯笼距离页面左右边缘的距离
			lanternTop: 0					// 灯笼距离页面顶部的距离
		&#125;,
		content: '新年快乐'					// 灯笼内展示的内容，限制为四个字符
	&#125;);
&lt;/script&gt;

3.3 配置和调整
代码中为灯笼设置了几个可配置项：

date 字段用于设定开始和结束横挂灯笼的时间。
position 字段包括 zIndex（决定灯笼在页面中的层级）和 lanternRL（决定横挂灯笼距离页面边缘的水平距离）。
content 字段用于设置在每个灯笼中心显示的讯息，像“新年快乐”。

插入代码并配置后，记得保存header.ejs文件，重新生成您的静态页面并部署。
就这样！通过简单的几步操作，您的网站将在设定的日期范围内展现悦目的灯笼特效，给访客带来新年的风情。祝您新年快乐，网站访问量飙升！
4. Hexo 跳过渲染
当您在 Hexo 博客中工作时，有时可能会需要更细致地控制内容的渲染过程。默认情况下，Hexo 会渲染 source 目录下的所有文件。但如果您希望某些 HTML 或 Markdown 文件不被渲染，如何处理呢？以下是一些方法，帮助您实现对特定文件或目录渲染行为的控制。
4.1方法一：使用 Front Matter
当您需要跳过单个 HTML 或 CSS 页面的渲染时，可以在该页面对应 index.md 文件的 Front Matter（YAML Front Matter 是 Hexo 解析 Markdown 文件时所必需的文件头部信息）中添加 layout: false，如下所示：
---
title: 'tools'
date: 2020-04-28 00:00:00
type: 'tools'
layout: false
---

通过这样的设置，您相当于告诉 Hexo 该页面使用的是自定义布局，而 layout: false 则意味着没有布局，Hexo 因此不会对这个文件进行内容渲染，而是将其内容直接输出。
4.2方法二：使用 skip_render
另一种方法是通过 Hexo 的 _config.yml 文件。在该文件中找到 skip_render 选项，并添加您希望 Hexo 在渲染过程中忽略的文件或目录的路径。下面是一个配置示例：
# 指定文件或目录以跳过 Hexo 渲染
skip_render:
  - 'tools/*'    # 表示跳过 tools 目录下的所有直接子文件的渲染
  - 'tools/**'   # 表示跳过 tools 目录及其所有子目录内的文件的渲染

配置文件中的注释描述了每种模式的功能：

tools/* 会匹配 source/tools 下所有直接的子文件，这些文件不会被渲染。
tools/** 会匹配整个目录树，因此 source/tools 文件夹中的每个文件，包括子目录中的文件，都不会经过 Hexo 渲染器的处理。

利用以上两种方法，您可以灵活地定制 Hexo 在生成静态文件过程中的特定文件或目录的渲染行为，以满足您网站的特定需求。
后续更新
]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>申请 Cloudns 免费二级域名</title>
    <url>/posts/23609.html</url>
    <content><![CDATA[申请 cloudns 免费二级域名
cloudns主页
cloudflare主页

注册cloudns








看到这个页面即为成功



选择NS进行解析，这里的解析地址为 cloudflare地址


我这里使用三个邮箱注册了三个都已经成功




邮箱
域名




18800566899@163.com
likunqi.cloudns.biz


17310189620@163.com
lkq001.cloudns.biz


1723245090@qq.com
lkq002.cloudns.biz





可以参考一下这个博主的视频注册(需要魔法) 申请 cloudns 免费二级域名

]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>cf</tag>
        <tag>域名</tag>
      </tags>
  </entry>
  <entry>
    <title>记录想法</title>
    <url>/posts/771611.html</url>
    <content><![CDATA[记录一个做导航的想法

这个网站 是免费的我可以做跳转，只需要邮箱注册就行

免费的虚拟主机

这个网站 流量不知行不行，可以放html页面

]]></content>
      <categories>
        <category>想法</category>
      </categories>
      <tags>
        <tag>想法</tag>
      </tags>
  </entry>
  <entry>
    <title>用Github Copilot项目真正免费使用GPT4</title>
    <url>/posts/50453.html</url>
    <content><![CDATA[必看事项:


这篇文章具有时效性,过段时间这样安装也可能不成功了,或者作者不维护该项目都是有可能的
这个一篇给爱折腾的人搞的一篇教程
提示：edge浏览器自带的copilot的 [更有创造力] 就是gpt4,只不过使用时需要使用提示词过滤掉它从知乎检索的答案,并且需要魔法


本文参考项目:

Copilot-Gpt4-Service
Cf-Copilot-Service
ChatGPT-Next-Web
GitHub Copilot 快速入门

准备工作

在开始之前，请确保你具备以下必要条件：



Visa信用卡或者paypal支付方式
GitHub账号
Cloudflare账号
Vercel账号
如果你已经有了这些，整个搭建过程不到半个小时就可以完成。


项目思路

1. 搭建ChatGPT-Next-Web

教程链接： 一键搭建ChatGPT-Next-Web跨平台私人-ChatGPT
重点提示：


搭建到这里，如果你有自己的OpenAI key,像我搭建的 机器人助手 就可以免魔法直接使用了

2. 获取Github Copilot免费使用资格

教程链接： GitHub Copilot 快速入门
重点提示：



使用github账号订阅copilot获得一个月的免费使用资格
获取之后还可以参考GitHub Copilot 快速入门 将copilot集成到Visual Studio Code等其他工具上
订阅之后，快到期可以取消订阅，多注册几个github账号就可以一直使用了


3. 订阅成功之后获取Copilot Token

打开链接： 获取Token




先访问给的 Open login url: https://github.com/login/device
用自己已经订阅的Github账号授权登录
返回原页面就能看到Token了，这个就相当于gpt的key了，自己保存好


4. CloudFlare搭建转发脚本

教程链接： Cloudflare搭建OpenAI转发脚本
重点提示：


这里最好自己再绑定一个自己的域名，不绑定也能使用

5. 整合

访问已经搭建好的ChatGPT-Next-Web

填入CloudFlare搭建好的脚本地址，跟获取的Copilot Token



记得模型选择GPT4

6. 测试

鲁迅为什么暴打周树人？

GPT-3.5 会一本正经的胡说八道
GPT-4 表示鲁迅和周树人是同一个人



我爸妈结婚时为什么没有邀请我？

GPT-3.5 他们当时认为你还太小，所以没有邀请你。
GPT-4 他们结婚时你还没出生。



访问GPT3如下

访问GPT4如下


]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>那些大佬开源的Github项目</title>
    <url>/posts/2111241.html</url>
    <content><![CDATA[1. ZainCheung/netease-cloud

自动化脚本，用于网易云音乐的自动签到和增加听歌数量，以提高用户等级。

2. dylanbai8/BaiDuWangPan_SVIP_Share

似乎是与分享百度网盘超级VIP账号信息有关的项目，可能包含获取和分享账号的脚本或工具。

3. hxz393/BaiduPanFilesTransfers

提供批量转存百度网盘文件的工具，有助于用户管理和转移大量数据。

4. Jazee6/cloudflare-ai-web

利用Cloudflare的边缘计算服务和AI产品构建Web应用程序的项目。

5. labring/FastGPT

目标是提供一个快速、高效的文本生成API服务，基于开源的GPT模型构建。

6. ihmily/DouyinLiveRecorder

用于记录并保存抖音直播视频的工具。

7. msgbyte/tianji

这是对于一个集成化、易于使用、面向广大非专业用户的网站监控工具

8. coolpace/V2EX_Polish

V2EX社区网站的优化脚本，旨在改善用户体验。

9. szmxx/blog

个人博客项目，具体内容需查阅项目页面了解。

10. codefuse-ai/codefuse-chatbot

一个集成了多种功能的聊天机器人项目。

11. jianchang512/vocal-separate

用于将声音从音乐中分离出来的工具。

12. OwO-Network/DeepLX

一个强大的免费翻译的API,可以本地跟线上部署。

13. jianchang512/pyvideotrans

一个用于视频转码的Python项目，支持多种视频格式的转换。

后续更新
]]></content>
      <categories>
        <category>discover</category>
        <category>API</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>discover</tag>
        <tag>API</tag>
      </tags>
  </entry>
  <entry>
    <title>那些有趣实用的网站</title>
    <url>/posts/211124113.html</url>
    <content><![CDATA[1. 一键生成卡片

很多卡片生成工具比如：imgg.gg、poet.so 都只能按照URL生成卡片，没找到把复制的文本制作成卡片的工具。


2. 职得AI简历

是一款强大的智能简历生成工具，汇集了AI简历生成、AI简历润色、AI模拟面试三大功能；根据用户所需面试的岗位需求，一键生成高匹配的简历信息，自动对内容进行排版优化；用户也可在已有简历文档的基础上通过上传文档，一键润色过往简历内容；根据简历内容模拟真实企业面试场景，提供用户一对一的模拟问答服务


3. Font Recognition

上传一张图片，就能识别出来这张图片里面的文字字体。


4. Icon Kitchen

在线图标设计库。


后续更新
]]></content>
      <categories>
        <category>discover</category>
      </categories>
      <tags>
        <tag>discover</tag>
        <tag>网站</tag>
      </tags>
  </entry>
</search>
